2021-10-29 12:28:08,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-29 12:28:08,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-29 12:28:09,093 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-29 12:28:09,173 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-29 12:28:09,173 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-29 12:28:09,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-29 12:28:09,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-29 12:28:09,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-29 12:28:09,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-29 12:28:09,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-29 12:28:09,261 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-29 12:28:09,264 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-29 12:28:09,272 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-29 12:28:09,274 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-29 12:28:09,274 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-29 12:28:09,274 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-29 12:28:09,285 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-29 12:28:09,287 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-29 12:28:09,287 INFO org.mortbay.log: jetty-6.1.26
2021-10-29 12:28:09,432 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-29 12:28:09,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-29 12:28:09,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-29 12:28:09,524 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-29 12:28:09,541 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-29 12:28:09,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-29 12:28:09,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-29 12:28:09,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-29 12:28:09,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-29 12:28:09,616 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-29 12:28:09,616 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-29 12:28:10,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:11,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:12,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:13,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:14,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:15,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:16,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:17,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:18,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:19,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:19,755 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-10-29 12:28:25,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:26,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:27,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:28,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:29,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:30,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:31,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:32,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:33,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:34,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:34,764 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-10-29 12:28:40,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:41,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:42,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:43,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:44,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:45,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:46,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:47,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:48,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 12:28:48,861 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 1358@hadoopmaster
2021-10-29 12:28:48,862 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:48,862 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-29 12:28:48,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:48,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:48,924 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-771322545-172.31.29.187-1635510519500 is not formatted for BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:48,924 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-29 12:28:48,924 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-771322545-172.31.29.187-1635510519500 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-771322545-172.31.29.187-1635510519500/current
2021-10-29 12:28:48,927 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-29 12:28:48,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=604006783;bpid=BP-771322545-172.31.29.187-1635510519500;lv=-56;nsInfo=lv=-60;cid=CID-a9829352-ca54-478f-8a9d-b26608f8a05f;nsid=604006783;c=0;bpid=BP-771322545-172.31.29.187-1635510519500;dnuuid=null
2021-10-29 12:28:48,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 4df4da47-106a-440d-bebc-73610c38ece5
2021-10-29 12:28:48,960 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-29 12:28:48,960 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-29 12:28:48,964 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-29 12:28:48,965 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:48,968 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-771322545-172.31.29.187-1635510519500 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-29 12:28:48,988 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-771322545-172.31.29.187-1635510519500 on /tmp/hadoop-ubuntu/dfs/data/current: 20ms
2021-10-29 12:28:48,988 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-771322545-172.31.29.187-1635510519500: 24ms
2021-10-29 12:28:48,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-771322545-172.31.29.187-1635510519500 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-29 12:28:48,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-771322545-172.31.29.187-1635510519500 on volume /tmp/hadoop-ubuntu/dfs/data/current: 1ms
2021-10-29 12:28:48,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-10-29 12:28:48,991 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635513822991 with interval 21600000
2021-10-29 12:28:49,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-771322545-172.31.29.187-1635510519500 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-29 12:28:49,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-771322545-172.31.29.187-1635510519500 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-29 12:28:49,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-29 12:28:49,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-771322545-172.31.29.187-1635510519500 (Datanode Uuid 4df4da47-106a-440d-bebc-73610c38ece5) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-29 12:28:49,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-771322545-172.31.29.187-1635510519500 (Datanode Uuid 4df4da47-106a-440d-bebc-73610c38ece5) service to hadoopmaster/172.31.29.187:8020
2021-10-29 12:28:49,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe32b7163b4,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-29 12:28:49,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:49,110 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-29 12:28:49,110 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-29 12:28:49,111 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-29 12:28:49,111 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-29 12:28:49,111 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-771322545-172.31.29.187-1635510519500
2021-10-29 12:28:49,114 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-771322545-172.31.29.187-1635510519500 to blockPoolScannerMap, new size=1
2021-10-29 12:33:14,750 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-29 12:33:14,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-29 12:36:46,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-29 12:36:46,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-29 12:36:47,419 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-29 12:36:47,516 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-29 12:36:47,516 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-29 12:36:47,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-29 12:36:47,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-29 12:36:47,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-29 12:36:47,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-29 12:36:47,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-29 12:36:47,601 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-29 12:36:47,604 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-29 12:36:47,612 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-29 12:36:47,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-29 12:36:47,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-29 12:36:47,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-29 12:36:47,626 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-29 12:36:47,628 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-29 12:36:47,628 INFO org.mortbay.log: jetty-6.1.26
2021-10-29 12:36:47,805 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-29 12:36:47,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-29 12:36:47,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-29 12:36:47,870 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-29 12:36:47,883 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-29 12:36:47,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-29 12:36:47,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-29 12:36:47,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-29 12:36:47,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-29 12:36:47,950 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-29 12:36:47,958 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-29 12:36:48,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 1301@hadoopmaster
2021-10-29 12:36:48,271 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,271 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-29 12:36:48,331 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,331 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,332 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643 is not formatted for BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,332 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-29 12:36:48,332 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-840138802-172.31.29.187-1635510950643 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current
2021-10-29 12:36:48,335 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-29 12:36:48,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=199133153;bpid=BP-840138802-172.31.29.187-1635510950643;lv=-56;nsInfo=lv=-60;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0;bpid=BP-840138802-172.31.29.187-1635510950643;dnuuid=null
2021-10-29 12:36:48,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 057955f0-64c4-4f1d-9a76-1f53690c49c6
2021-10-29 12:36:48,370 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-29 12:36:48,370 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-29 12:36:48,374 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-29 12:36:48,374 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,375 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-840138802-172.31.29.187-1635510950643 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-29 12:36:48,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-840138802-172.31.29.187-1635510950643 on /tmp/hadoop-ubuntu/dfs/data/current: 10ms
2021-10-29 12:36:48,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-840138802-172.31.29.187-1635510950643: 11ms
2021-10-29 12:36:48,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-840138802-172.31.29.187-1635510950643 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-29 12:36:48,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-840138802-172.31.29.187-1635510950643 on volume /tmp/hadoop-ubuntu/dfs/data/current: 0ms
2021-10-29 12:36:48,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-10-29 12:36:48,389 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635528333389 with interval 21600000
2021-10-29 12:36:48,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-29 12:36:48,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-29 12:36:48,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-29 12:36:48,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid 057955f0-64c4-4f1d-9a76-1f53690c49c6) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-29 12:36:48,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid 057955f0-64c4-4f1d-9a76-1f53690c49c6) service to hadoopmaster/172.31.29.187:8020
2021-10-29 12:36:48,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x25571546bf,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-29 12:36:48,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,631 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-29 12:36:48,631 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-29 12:36:48,632 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-29 12:36:48,632 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-29 12:36:48,633 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 12:36:48,636 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-840138802-172.31.29.187-1635510950643 to blockPoolScannerMap, new size=1
2021-10-29 12:37:43,420 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57470 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:43,744 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57474 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:44,054 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57476 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:44,355 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57478 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:45,678 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57480 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:46,203 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57482 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:46,518 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57484 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:46,818 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing unknown operation  src: /219.74.118.59:57486 dst: /172.31.29.187:50010
java.io.IOException: Version Mismatch (Expected: 28, Received: 5635 )
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:60)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:216)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 12:37:49,639 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56954 got version 0 expected version 9
2021-10-29 12:37:49,889 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56956 got version 0 expected version 9
2021-10-29 12:37:50,195 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56958 got version 0 expected version 9
2021-10-29 12:37:50,506 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56960 got version 0 expected version 9
2021-10-29 12:37:51,813 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56964 got version 0 expected version 9
2021-10-29 12:37:52,345 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56966 got version 0 expected version 9
2021-10-29 12:37:52,655 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56970 got version 0 expected version 9
2021-10-29 12:37:52,964 WARN org.apache.hadoop.ipc.Server: Incorrect header or version mismatch from 219.74.118.59:56972 got version 0 expected version 9
2021-10-29 12:46:52,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741825_1001 src: /172.31.29.187:42342 dest: /172.31.29.187:50010
2021-10-29 12:46:53,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42342, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741825_1001, duration: 70209901
2021-10-29 12:46:53,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741826_1002 src: /172.31.29.187:42346 dest: /172.31.29.187:50010
2021-10-29 12:46:53,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42346, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741826_1002, duration: 70116328
2021-10-29 12:46:53,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741827_1003 src: /172.31.29.187:42350 dest: /172.31.29.187:50010
2021-10-29 12:46:53,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42350, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741827_1003, duration: 6432062
2021-10-29 12:46:53,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741828_1004 src: /172.31.29.187:42354 dest: /172.31.29.187:50010
2021-10-29 12:46:53,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42354, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741828_1004, duration: 7939970
2021-10-29 12:46:53,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741829_1005 src: /172.31.29.187:42358 dest: /172.31.29.187:50010
2021-10-29 12:46:53,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42358, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741829_1005, duration: 4399298
2021-10-29 12:46:53,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741830_1006 src: /172.31.29.187:42362 dest: /172.31.29.187:50010
2021-10-29 12:46:53,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42362, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741830_1006, duration: 9937296
2021-10-29 12:46:53,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741831_1007 src: /172.31.29.187:42366 dest: /172.31.29.187:50010
2021-10-29 12:46:53,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42366, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741831_1007, duration: 5513997
2021-10-29 12:46:53,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741832_1008 src: /172.31.29.187:42370 dest: /172.31.29.187:50010
2021-10-29 12:46:53,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42370, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741832_1008, duration: 8040404
2021-10-29 12:46:53,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741833_1009 src: /172.31.29.187:42374 dest: /172.31.29.187:50010
2021-10-29 12:46:53,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42374, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741833_1009, duration: 6872833
2021-10-29 12:46:53,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:53,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741834_1010 src: /172.31.29.187:42378 dest: /172.31.29.187:50010
2021-10-29 12:46:53,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42378, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741834_1010, duration: 5971102
2021-10-29 12:46:53,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:54,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741835_1011 src: /172.31.29.187:42386 dest: /172.31.29.187:50010
2021-10-29 12:46:54,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42386, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741835_1011, duration: 13720496
2021-10-29 12:46:54,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:54,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741836_1012 src: /172.31.29.187:42390 dest: /172.31.29.187:50010
2021-10-29 12:46:54,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42390, dest: /172.31.29.187:50010, bytes: 1467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741836_1012, duration: 12782996
2021-10-29 12:46:54,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:54,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741837_1013 src: /172.31.29.187:42394 dest: /172.31.29.187:50010
2021-10-29 12:46:54,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42394, dest: /172.31.29.187:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741837_1013, duration: 6393532
2021-10-29 12:46:54,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:54,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741838_1014 src: /172.31.29.187:42398 dest: /172.31.29.187:50010
2021-10-29 12:46:54,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42398, dest: /172.31.29.187:50010, bytes: 88668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-778319708_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741838_1014, duration: 6817250
2021-10-29 12:46:54,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:46:58,427 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741825_1001
2021-10-29 12:47:03,433 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741830_1006
2021-10-29 12:47:11,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741840_1016 src: /172.31.18.188:45122 dest: /172.31.29.187:50010
2021-10-29 12:47:36,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741841_1017 src: /172.31.29.187:42456 dest: /172.31.29.187:50010
2021-10-29 12:47:36,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42456, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_attempt_1635511362668_0001_r_000000_0_-223465088_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741841_1017, duration: 26983977
2021-10-29 12:47:36,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:47:36,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741842_1018 src: /172.31.29.187:42460 dest: /172.31.29.187:50010
2021-10-29 12:47:36,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42460, dest: /172.31.29.187:50010, bytes: 97, op: HDFS_WRITE, cliID: DFSClient_attempt_1635511362668_0001_r_000000_0_-223465088_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741842_1018, duration: 6477074
2021-10-29 12:47:36,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:47:36,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45122, dest: /172.31.29.187:50010, bytes: 91625, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238107915_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741840_1016, duration: 24716214167
2021-10-29 12:47:36,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 12:47:36,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021 src: /172.31.18.188:45160 dest: /172.31.29.187:50010
2021-10-29 12:47:36,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45160, dest: /172.31.29.187:50010, bytes: 105454, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238107915_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021, duration: 5737873
2021-10-29 12:47:36,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 12:47:39,541 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2021-10-29 12:47:39,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2021-10-29 12:47:39,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2021-10-29 12:47:39,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2021-10-29 12:47:39,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2021-10-29 12:47:39,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2021-10-29 12:47:39,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2021-10-29 12:47:39,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741825_1001 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741825
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741826_1002 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741826
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741827_1003 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741827
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741828_1004 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741828
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741829_1005 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741829
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741830
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741831_1007 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741831
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741832_1008 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741832
2021-10-29 12:47:39,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741834_1010 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741834
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741835_1011 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741835
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741836_1012 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741836
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741837
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741838_1014 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741838
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741840_1016 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741840
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741841_1017 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741841
2021-10-29 12:47:39,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741842_1018 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741842
2021-10-29 12:47:43,441 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021
2021-10-29 12:47:43,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022 src: /172.31.18.188:45168 dest: /172.31.29.187:50010
2021-10-29 12:47:43,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45168, dest: /172.31.29.187:50010, bytes: 92201, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_694164482_77, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022, duration: 42915994
2021-10-29 12:47:43,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 12:47:44,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024 src: /172.31.29.187:42474 dest: /172.31.29.187:50010
2021-10-29 12:47:44,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42474, dest: /172.31.29.187:50010, bytes: 24551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-213211244_79, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024, duration: 20691918
2021-10-29 12:47:44,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 12:47:53,444 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024
2021-10-29 13:02:40,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741849_1025 src: /172.31.29.187:42530 dest: /172.31.29.187:50010
2021-10-29 13:02:40,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42530, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741849_1025, duration: 34050081
2021-10-29 13:02:40,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741850_1026 src: /172.31.29.187:42534 dest: /172.31.29.187:50010
2021-10-29 13:02:40,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42534, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741850_1026, duration: 5210379
2021-10-29 13:02:40,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741851_1027 src: /172.31.29.187:42538 dest: /172.31.29.187:50010
2021-10-29 13:02:40,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42538, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741851_1027, duration: 6729240
2021-10-29 13:02:40,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741852_1028 src: /172.31.29.187:42542 dest: /172.31.29.187:50010
2021-10-29 13:02:40,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42542, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741852_1028, duration: 5110194
2021-10-29 13:02:40,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741853_1029 src: /172.31.29.187:42546 dest: /172.31.29.187:50010
2021-10-29 13:02:40,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42546, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741853_1029, duration: 5969207
2021-10-29 13:02:40,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741854_1030 src: /172.31.29.187:42550 dest: /172.31.29.187:50010
2021-10-29 13:02:40,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42550, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741854_1030, duration: 4761595
2021-10-29 13:02:40,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741855_1031 src: /172.31.29.187:42554 dest: /172.31.29.187:50010
2021-10-29 13:02:40,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42554, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741855_1031, duration: 5872199
2021-10-29 13:02:40,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741856_1032 src: /172.31.29.187:42558 dest: /172.31.29.187:50010
2021-10-29 13:02:40,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42558, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741856_1032, duration: 4380572
2021-10-29 13:02:40,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741857_1033 src: /172.31.29.187:42562 dest: /172.31.29.187:50010
2021-10-29 13:02:40,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42562, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741857_1033, duration: 4905130
2021-10-29 13:02:40,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741858_1034 src: /172.31.29.187:42566 dest: /172.31.29.187:50010
2021-10-29 13:02:40,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42566, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741858_1034, duration: 3852539
2021-10-29 13:02:40,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741859_1035 src: /172.31.29.187:42572 dest: /172.31.29.187:50010
2021-10-29 13:02:40,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42572, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741859_1035, duration: 9408495
2021-10-29 13:02:40,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741860_1036 src: /172.31.29.187:42576 dest: /172.31.29.187:50010
2021-10-29 13:02:40,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42576, dest: /172.31.29.187:50010, bytes: 1457, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741860_1036, duration: 8555893
2021-10-29 13:02:40,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:40,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741861_1037 src: /172.31.29.187:42580 dest: /172.31.29.187:50010
2021-10-29 13:02:40,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42580, dest: /172.31.29.187:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741861_1037, duration: 6461906
2021-10-29 13:02:40,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:41,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741862_1038 src: /172.31.29.187:42584 dest: /172.31.29.187:50010
2021-10-29 13:02:41,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42584, dest: /172.31.29.187:50010, bytes: 88666, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1714980134_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741862_1038, duration: 11240431
2021-10-29 13:02:41,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:02:48,484 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741860_1036
2021-10-29 13:03:10,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741864_1040 src: /172.31.16.191:52000 dest: /172.31.29.187:50010
2021-10-29 13:03:18,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52000, dest: /172.31.29.187:50010, bytes: 91581, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-532954318_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741864_1040, duration: 7596499598
2021-10-29 13:03:18,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:03:18,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044 src: /172.31.16.191:52066 dest: /172.31.29.187:50010
2021-10-29 13:03:18,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52066, dest: /172.31.29.187:50010, bytes: 91581, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-532954318_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044, duration: 6585527
2021-10-29 13:03:18,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:03:18,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045 src: /172.31.16.191:52070 dest: /172.31.29.187:50010
2021-10-29 13:03:18,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52070, dest: /172.31.29.187:50010, bytes: 105452, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-532954318_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045, duration: 6042274
2021-10-29 13:03:18,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:03:23,492 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741856_1032 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-29 13:03:24,586 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741852_1028 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741853_1029 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741854_1030 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741856_1032 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741856
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741857_1033 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741857
2021-10-29 13:03:24,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741858_1034 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741858
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741859_1035 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741860_1036 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741861_1037 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741861
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741862_1038 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741862
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741864_1040 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741864
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741849_1025 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741849
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741850_1026 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741850
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741851_1027 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741851
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741852_1028 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741852
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741853_1029 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741853
2021-10-29 13:03:24,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741854_1030 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741854
2021-10-29 13:03:24,589 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741855_1031 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741855
2021-10-29 13:05:18,593 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "hadoopmaster/172.31.29.187"; destination host is: "hadoopmaster":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	at org.apache.hadoop.ipc.Client.call(Client.java:1400)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:617)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:715)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:889)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)
2021-10-29 13:05:22,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-29 13:05:23,505 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-29 13:05:23,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-29 13:07:23,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-29 13:07:23,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-29 13:07:23,875 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-29 13:07:23,964 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-29 13:07:23,964 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-29 13:07:23,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-29 13:07:23,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-29 13:07:23,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-29 13:07:23,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-29 13:07:23,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-29 13:07:24,056 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-29 13:07:24,060 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-29 13:07:24,069 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-29 13:07:24,070 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-29 13:07:24,070 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-29 13:07:24,070 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-29 13:07:24,083 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-29 13:07:24,086 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-29 13:07:24,086 INFO org.mortbay.log: jetty-6.1.26
2021-10-29 13:07:24,239 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-29 13:07:24,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-29 13:07:24,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-29 13:07:24,297 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-29 13:07:24,309 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-29 13:07:24,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-29 13:07:24,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-29 13:07:24,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-29 13:07:24,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-29 13:07:24,369 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-29 13:07:24,369 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-29 13:07:24,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 3969@hadoopmaster
2021-10-29 13:07:24,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-840138802-172.31.29.187-1635510950643
2021-10-29 13:07:24,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643
2021-10-29 13:07:24,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-29 13:07:24,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=199133153;bpid=BP-840138802-172.31.29.187-1635510950643;lv=-56;nsInfo=lv=-60;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0;bpid=BP-840138802-172.31.29.187-1635510950643;dnuuid=057955f0-64c4-4f1d-9a76-1f53690c49c6
2021-10-29 13:07:24,723 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-29 13:07:24,723 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-29 13:07:24,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-29 13:07:24,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 13:07:24,749 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-840138802-172.31.29.187-1635510950643 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-29 13:07:24,756 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current: 473019
2021-10-29 13:07:24,762 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-840138802-172.31.29.187-1635510950643 on /tmp/hadoop-ubuntu/dfs/data/current: 12ms
2021-10-29 13:07:24,762 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-840138802-172.31.29.187-1635510950643: 16ms
2021-10-29 13:07:24,762 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-840138802-172.31.29.187-1635510950643 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-29 13:07:24,765 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-840138802-172.31.29.187-1635510950643 on volume /tmp/hadoop-ubuntu/dfs/data/current: 3ms
2021-10-29 13:07:24,765 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2021-10-29 13:07:24,767 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635523999767 with interval 21600000
2021-10-29 13:07:24,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-29 13:07:24,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-29 13:07:24,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-29 13:07:24,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid 057955f0-64c4-4f1d-9a76-1f53690c49c6) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=331
2021-10-29 13:07:24,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-840138802-172.31.29.187-1635510950643 (Datanode Uuid 057955f0-64c4-4f1d-9a76-1f53690c49c6) service to hadoopmaster/172.31.29.187:8020
2021-10-29 13:07:24,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1d0e597b92e,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-29 13:07:24,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 13:07:24,967 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-29 13:07:24,967 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-29 13:07:24,968 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-29 13:07:24,968 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-29 13:07:24,969 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 13:07:24,973 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-840138802-172.31.29.187-1635510950643 to blockPoolScannerMap, new size=1
2021-10-29 13:07:29,810 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022
2021-10-29 13:07:29,823 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044
2021-10-29 13:08:00,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741872_1048 src: /172.31.29.187:42654 dest: /172.31.29.187:50010
2021-10-29 13:08:00,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42654, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741872_1048, duration: 80425316
2021-10-29 13:08:00,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:00,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741873_1049 src: /172.31.29.187:42658 dest: /172.31.29.187:50010
2021-10-29 13:08:00,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42658, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741873_1049, duration: 68014757
2021-10-29 13:08:00,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:00,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741874_1050 src: /172.31.29.187:42662 dest: /172.31.29.187:50010
2021-10-29 13:08:00,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42662, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741874_1050, duration: 9968703
2021-10-29 13:08:00,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:00,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741875_1051 src: /172.31.29.187:42666 dest: /172.31.29.187:50010
2021-10-29 13:08:00,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42666, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741875_1051, duration: 9116178
2021-10-29 13:08:00,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:00,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741876_1052 src: /172.31.29.187:42670 dest: /172.31.29.187:50010
2021-10-29 13:08:00,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42670, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741876_1052, duration: 10621707
2021-10-29 13:08:00,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741877_1053 src: /172.31.29.187:42674 dest: /172.31.29.187:50010
2021-10-29 13:08:01,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42674, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741877_1053, duration: 7723165
2021-10-29 13:08:01,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741878_1054 src: /172.31.29.187:42678 dest: /172.31.29.187:50010
2021-10-29 13:08:01,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42678, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741878_1054, duration: 6334291
2021-10-29 13:08:01,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741879_1055 src: /172.31.29.187:42682 dest: /172.31.29.187:50010
2021-10-29 13:08:01,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42682, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741879_1055, duration: 6167462
2021-10-29 13:08:01,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741880_1056 src: /172.31.29.187:42686 dest: /172.31.29.187:50010
2021-10-29 13:08:01,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42686, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741880_1056, duration: 6366666
2021-10-29 13:08:01,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741881_1057 src: /172.31.29.187:42690 dest: /172.31.29.187:50010
2021-10-29 13:08:01,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42690, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741881_1057, duration: 7885010
2021-10-29 13:08:01,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741882_1058 src: /172.31.29.187:42696 dest: /172.31.29.187:50010
2021-10-29 13:08:01,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42696, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741882_1058, duration: 24594905
2021-10-29 13:08:01,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741883_1059 src: /172.31.29.187:42700 dest: /172.31.29.187:50010
2021-10-29 13:08:01,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42700, dest: /172.31.29.187:50010, bytes: 1467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741883_1059, duration: 28839924
2021-10-29 13:08:01,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741884_1060 src: /172.31.29.187:42704 dest: /172.31.29.187:50010
2021-10-29 13:08:01,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42704, dest: /172.31.29.187:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741884_1060, duration: 8137721
2021-10-29 13:08:01,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741884_1060, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:01,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741885_1061 src: /172.31.29.187:42708 dest: /172.31.29.187:50010
2021-10-29 13:08:01,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42708, dest: /172.31.29.187:50010, bytes: 88672, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-577487649_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741885_1061, duration: 20136705
2021-10-29 13:08:01,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741885_1061, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:03,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741882_1058 to 172.31.16.191:50010 
2021-10-29 13:08:03,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741882_1058 (numBytes=270356) to /172.31.16.191:50010
2021-10-29 13:08:09,833 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741884_1060
2021-10-29 13:08:36,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741890_1066 src: /172.31.18.188:45388 dest: /172.31.29.187:50010
2021-10-29 13:08:36,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45388, dest: /172.31.29.187:50010, bytes: 357, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1568314008_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741890_1066, duration: 3955842
2021-10-29 13:08:36,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741890_1066, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:08:43,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069 src: /172.31.18.188:45406 dest: /172.31.29.187:50010
2021-10-29 13:08:44,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45406, dest: /172.31.29.187:50010, bytes: 117038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-283505146_91, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069, duration: 41813341
2021-10-29 13:08:44,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:08:44,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070 src: /172.31.29.187:42790 dest: /172.31.29.187:50010
2021-10-29 13:08:44,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42790, dest: /172.31.29.187:50010, bytes: 20480, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1479466889_93, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070, duration: 18359208
2021-10-29 13:08:44,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:08:44,845 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741890_1066
2021-10-29 13:08:45,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741872_1048 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741872 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741873_1049 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741873 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741874_1050 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741874 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741875_1051 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741875 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741876_1052 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741876 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741877_1053 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741877 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741878_1054 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741878 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741879_1055 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741879 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741880_1056 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741880 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741881_1057 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741881 for deletion
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741872_1048 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741872
2021-10-29 13:08:45,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741882_1058 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741882 for deletion
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741883_1059 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741883 for deletion
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741873_1049 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741873
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741884_1060 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741884 for deletion
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741874_1050 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741874
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741885_1061 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741885 for deletion
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741875_1051 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741875
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741876_1052 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741876
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741877_1053 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741877
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741878_1054 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741878
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741879_1055 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741879
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741880_1056 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741880
2021-10-29 13:08:45,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741881_1057 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741881
2021-10-29 13:08:45,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741882_1058 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741882
2021-10-29 13:08:45,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741883_1059 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741883
2021-10-29 13:08:45,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741884_1060 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741884
2021-10-29 13:08:45,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741885_1061 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741885
2021-10-29 13:08:49,850 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069
2021-10-29 13:09:01,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741895_1071 src: /172.31.29.187:42798 dest: /172.31.29.187:50010
2021-10-29 13:09:01,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42798, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741895_1071, duration: 34136552
2021-10-29 13:09:01,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741895_1071, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741896_1072 src: /172.31.29.187:42802 dest: /172.31.29.187:50010
2021-10-29 13:09:01,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42802, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741896_1072, duration: 9006606
2021-10-29 13:09:01,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741896_1072, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741897_1073 src: /172.31.29.187:42806 dest: /172.31.29.187:50010
2021-10-29 13:09:01,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42806, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741897_1073, duration: 6729002
2021-10-29 13:09:01,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741897_1073, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741898_1074 src: /172.31.29.187:42810 dest: /172.31.29.187:50010
2021-10-29 13:09:01,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42810, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741898_1074, duration: 9681405
2021-10-29 13:09:01,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741898_1074, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741899_1075 src: /172.31.29.187:42814 dest: /172.31.29.187:50010
2021-10-29 13:09:01,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42814, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741899_1075, duration: 4301612
2021-10-29 13:09:01,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741899_1075, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741900_1076 src: /172.31.29.187:42818 dest: /172.31.29.187:50010
2021-10-29 13:09:01,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42818, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741900_1076, duration: 19870406
2021-10-29 13:09:01,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741900_1076, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741901_1077 src: /172.31.29.187:42822 dest: /172.31.29.187:50010
2021-10-29 13:09:01,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42822, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741901_1077, duration: 14934067
2021-10-29 13:09:01,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741901_1077, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741902_1078 src: /172.31.29.187:42826 dest: /172.31.29.187:50010
2021-10-29 13:09:01,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42826, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741902_1078, duration: 9507156
2021-10-29 13:09:01,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741902_1078, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741903_1079 src: /172.31.29.187:42830 dest: /172.31.29.187:50010
2021-10-29 13:09:01,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42830, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741903_1079, duration: 27092294
2021-10-29 13:09:01,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741903_1079, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:01,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741904_1080 src: /172.31.29.187:42834 dest: /172.31.29.187:50010
2021-10-29 13:09:02,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42834, dest: /172.31.29.187:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741904_1080, duration: 16453902
2021-10-29 13:09:02,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741904_1080, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:02,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741905_1081 src: /172.31.29.187:42840 dest: /172.31.29.187:50010
2021-10-29 13:09:02,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42840, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741905_1081, duration: 34569123
2021-10-29 13:09:02,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741905_1081, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:02,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741906_1082 src: /172.31.29.187:42844 dest: /172.31.29.187:50010
2021-10-29 13:09:02,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42844, dest: /172.31.29.187:50010, bytes: 1457, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741906_1082, duration: 16759031
2021-10-29 13:09:02,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741906_1082, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:02,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741907_1083 src: /172.31.29.187:42848 dest: /172.31.29.187:50010
2021-10-29 13:09:02,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42848, dest: /172.31.29.187:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741907_1083, duration: 11494982
2021-10-29 13:09:02,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741907_1083, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:02,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741908_1084 src: /172.31.29.187:42852 dest: /172.31.29.187:50010
2021-10-29 13:09:02,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42852, dest: /172.31.29.187:50010, bytes: 88670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-809720645_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741908_1084, duration: 8447195
2021-10-29 13:09:02,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741908_1084, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:09:09,860 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741907_1083
2021-10-29 13:09:32,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741910_1086 src: /172.31.18.188:45502 dest: /172.31.29.187:50010
2021-10-29 13:09:40,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45502, dest: /172.31.29.187:50010, bytes: 91581, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2130483652_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741910_1086, duration: 8480876583
2021-10-29 13:09:40,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741910_1086, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:09:40,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741913_1089 src: /172.31.18.188:45568 dest: /172.31.29.187:50010
2021-10-29 13:09:40,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45568, dest: /172.31.29.187:50010, bytes: 357, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2130483652_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741913_1089, duration: 11615810
2021-10-29 13:09:40,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741913_1089, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:09:40,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090 src: /172.31.18.188:45574 dest: /172.31.29.187:50010
2021-10-29 13:09:40,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45574, dest: /172.31.29.187:50010, bytes: 91581, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2130483652_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090, duration: 12051677
2021-10-29 13:09:40,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:09:47,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092 src: /172.31.18.188:45586 dest: /172.31.29.187:50010
2021-10-29 13:09:47,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45586, dest: /172.31.29.187:50010, bytes: 122609, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-530989544_91, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092, duration: 6020949
2021-10-29 13:09:47,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:09:48,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741890_1066 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741890 for deletion
2021-10-29 13:09:48,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741895_1071 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741895 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741896_1072 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741896 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741897_1073 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741897 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741890_1066 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741890
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741898_1074 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741898 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741899_1075 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741899 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741895_1071 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741895
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741900_1076 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741900 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741896_1072 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741896
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741901_1077 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741901 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741897_1073 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741897
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741902_1078 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741902 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741898_1074 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741898
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741903_1079 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741903 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741899_1075 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741899
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741900_1076 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741900
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741901_1077 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741901
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741904_1080 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741904 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741902_1078 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741902
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741905_1081 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741905 for deletion
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741903_1079 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741903
2021-10-29 13:09:48,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741906_1082 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741906 for deletion
2021-10-29 13:09:48,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741904_1080 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741904
2021-10-29 13:09:48,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741907_1083 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741907 for deletion
2021-10-29 13:09:48,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741905_1081 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741905
2021-10-29 13:09:48,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741906_1082 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741906
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741908_1084 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741908 for deletion
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741907_1083 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741907
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741910_1086 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741910 for deletion
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741908_1084 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741908
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741913_1089 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741913 for deletion
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741910_1086 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741910
2021-10-29 13:09:48,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741913_1089 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741913
2021-10-29 13:09:49,876 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090
2021-10-29 13:09:54,880 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092
2021-10-29 13:15:46,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741918_1094 src: /172.31.29.187:42924 dest: /172.31.29.187:50010
2021-10-29 13:15:46,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42924, dest: /172.31.29.187:50010, bytes: 2946272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2093390965_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741918_1094, duration: 64730187
2021-10-29 13:15:46,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741918_1094, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:15:56,581 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741918_1094
2021-10-29 13:20:07,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741919_1095 src: /172.31.29.187:42944 dest: /172.31.29.187:50010
2021-10-29 13:20:07,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42944, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1280269407_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741919_1095, duration: 27769640
2021-10-29 13:20:07,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741919_1095, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:20:07,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741920_1096 src: /172.31.29.187:42948 dest: /172.31.29.187:50010
2021-10-29 13:20:07,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42948, dest: /172.31.29.187:50010, bytes: 102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1280269407_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741920_1096, duration: 10471705
2021-10-29 13:20:07,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741920_1096, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:20:07,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741921_1097 src: /172.31.29.187:42952 dest: /172.31.29.187:50010
2021-10-29 13:20:07,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42952, dest: /172.31.29.187:50010, bytes: 39, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1280269407_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741921_1097, duration: 6617366
2021-10-29 13:20:07,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741921_1097, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:20:07,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741922_1098 src: /172.31.29.187:42956 dest: /172.31.29.187:50010
2021-10-29 13:20:07,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42956, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1280269407_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741922_1098, duration: 11555869
2021-10-29 13:20:07,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741922_1098, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:20:09,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741919_1095 to 172.31.18.188:50010 
2021-10-29 13:20:09,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741919_1095 (numBytes=270356) to /172.31.18.188:50010
2021-10-29 13:20:16,632 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741922_1098
2021-10-29 13:20:22,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741924_1100 src: /172.31.16.191:52198 dest: /172.31.29.187:50010
2021-10-29 13:20:26,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741925_1101 src: /172.31.29.187:42982 dest: /172.31.29.187:50010
2021-10-29 13:20:26,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42982, dest: /172.31.29.187:50010, bytes: 768981, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0004_r_000000_0_2094417899_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741925_1101, duration: 116460478
2021-10-29 13:20:26,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741925_1101, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:20:26,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52198, dest: /172.31.29.187:50010, bytes: 33895, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1337704610_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741924_1100, duration: 4739213267
2021-10-29 13:20:26,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741924_1100, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:20:26,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741928_1104 src: /172.31.16.191:52216 dest: /172.31.29.187:50010
2021-10-29 13:20:26,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52216, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1337704610_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741928_1104, duration: 5358247
2021-10-29 13:20:26,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741928_1104, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:20:30,890 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741920_1096 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741920 for deletion
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741921_1097 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741921 for deletion
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741922_1098 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741922 for deletion
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741920_1096 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741920
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741924_1100 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741924 for deletion
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741919_1095 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741919 for deletion
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741921_1097 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741921
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741922_1098 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741922
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741924_1100 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741924
2021-10-29 13:20:30,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741919_1095 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741919
2021-10-29 13:20:34,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105 src: /172.31.16.191:52224 dest: /172.31.29.187:50010
2021-10-29 13:20:34,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52224, dest: /172.31.29.187:50010, bytes: 38281, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-552202500_178, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105, duration: 3555396
2021-10-29 13:20:34,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:20:34,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106 src: /172.31.29.187:42994 dest: /172.31.29.187:50010
2021-10-29 13:20:34,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:42994, dest: /172.31.29.187:50010, bytes: 6189, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1699666250_195, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106, duration: 5399236
2021-10-29 13:20:34,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:20:37,040 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741925_1101
2021-10-29 13:20:42,042 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105
2021-10-29 13:22:36,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741925_1101 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741925 for deletion
2021-10-29 13:22:36,898 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741925_1101 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741925
2021-10-29 13:22:46,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741931_1107 src: /172.31.29.187:43018 dest: /172.31.29.187:50010
2021-10-29 13:22:46,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43018, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1141039325_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741931_1107, duration: 39222714
2021-10-29 13:22:46,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741931_1107, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:46,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741932_1108 src: /172.31.29.187:43022 dest: /172.31.29.187:50010
2021-10-29 13:22:46,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43022, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1141039325_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741932_1108, duration: 13710663
2021-10-29 13:22:46,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741932_1108, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:46,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741933_1109 src: /172.31.29.187:43026 dest: /172.31.29.187:50010
2021-10-29 13:22:46,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43026, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1141039325_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741933_1109, duration: 19430005
2021-10-29 13:22:46,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741933_1109, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:46,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741934_1110 src: /172.31.29.187:43030 dest: /172.31.29.187:50010
2021-10-29 13:22:46,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43030, dest: /172.31.29.187:50010, bytes: 10910814, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1141039325_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741934_1110, duration: 135457745
2021-10-29 13:22:46,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741934_1110, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:46,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741935_1111 src: /172.31.29.187:43034 dest: /172.31.29.187:50010
2021-10-29 13:22:47,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43034, dest: /172.31.29.187:50010, bytes: 99220506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1141039325_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741935_1111, duration: 951390603
2021-10-29 13:22:47,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741935_1111, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:52,875 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741931_1107
2021-10-29 13:22:56,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741936_1112 src: /172.31.29.187:43040 dest: /172.31.29.187:50010
2021-10-29 13:22:56,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43040, dest: /172.31.29.187:50010, bytes: 2946272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_784329149_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741936_1112, duration: 58853105
2021-10-29 13:22:56,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741936_1112, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:56,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741937_1113 src: /172.31.29.187:43044 dest: /172.31.29.187:50010
2021-10-29 13:22:56,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43044, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_784329149_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741937_1113, duration: 11061236
2021-10-29 13:22:56,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741937_1113, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:56,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741938_1114 src: /172.31.29.187:43048 dest: /172.31.29.187:50010
2021-10-29 13:22:56,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43048, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_784329149_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741938_1114, duration: 14469452
2021-10-29 13:22:56,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741938_1114, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:56,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741939_1115 src: /172.31.29.187:43052 dest: /172.31.29.187:50010
2021-10-29 13:22:56,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43052, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_784329149_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741939_1115, duration: 15680671
2021-10-29 13:22:56,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741939_1115, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:56,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741940_1116 src: /172.31.29.187:43056 dest: /172.31.29.187:50010
2021-10-29 13:22:56,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43056, dest: /172.31.29.187:50010, bytes: 10910814, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_784329149_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741940_1116, duration: 118562247
2021-10-29 13:22:56,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741940_1116, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:22:56,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741941_1117 src: /172.31.29.187:43060 dest: /172.31.29.187:50010
2021-10-29 13:22:57,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43060, dest: /172.31.29.187:50010, bytes: 99220506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_784329149_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741941_1117, duration: 900130626
2021-10-29 13:22:57,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741941_1117, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741931_1107 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741931 for deletion
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741932_1108 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741932 for deletion
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741933_1109 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741933 for deletion
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741918_1094 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741918 for deletion
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741934_1110 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741934 for deletion
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741935_1111 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741935 for deletion
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741931_1107 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741931
2021-10-29 13:23:00,899 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741932_1108 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741932
2021-10-29 13:23:00,900 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741933_1109 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741933
2021-10-29 13:23:00,900 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741918_1094 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741918
2021-10-29 13:23:00,902 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741934_1110 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741934
2021-10-29 13:23:00,902 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741935_1111 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741935
2021-10-29 13:23:21,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741942_1118 src: /172.31.29.187:43070 dest: /172.31.29.187:50010
2021-10-29 13:23:21,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43070, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1244144528_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741942_1118, duration: 30301828
2021-10-29 13:23:21,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741942_1118, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:23:21,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741943_1119 src: /172.31.29.187:43074 dest: /172.31.29.187:50010
2021-10-29 13:23:21,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43074, dest: /172.31.29.187:50010, bytes: 582, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1244144528_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741943_1119, duration: 7716150
2021-10-29 13:23:21,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741943_1119, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:23:21,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741944_1120 src: /172.31.29.187:43078 dest: /172.31.29.187:50010
2021-10-29 13:23:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43078, dest: /172.31.29.187:50010, bytes: 192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1244144528_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741944_1120, duration: 10073961
2021-10-29 13:23:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741944_1120, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:23:21,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741945_1121 src: /172.31.29.187:43082 dest: /172.31.29.187:50010
2021-10-29 13:23:21,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43082, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1244144528_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741945_1121, duration: 5137480
2021-10-29 13:23:21,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741945_1121, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:23:27,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741942_1118 to 172.31.18.188:50010 
2021-10-29 13:23:27,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741942_1118 (numBytes=270356) to /172.31.18.188:50010
2021-10-29 13:24:26,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126 src: /172.31.18.188:45734 dest: /172.31.29.187:50010
2021-10-29 13:24:26,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45734, dest: /172.31.29.187:50010, bytes: 73188, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_193457234_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126, duration: 4816100
2021-10-29 13:24:26,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:24:27,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127 src: /172.31.18.188:45738 dest: /172.31.29.187:50010
2021-10-29 13:24:27,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45738, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_193457234_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127, duration: 4603211
2021-10-29 13:24:27,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:24:33,277 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741935_1111
2021-10-29 13:24:33,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128 src: /172.31.18.188:45746 dest: /172.31.29.187:50010
2021-10-29 13:24:33,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45746, dest: /172.31.29.187:50010, bytes: 117253, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1049769556_317, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128, duration: 7115917
2021-10-29 13:24:33,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:24:34,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129 src: /172.31.29.187:43128 dest: /172.31.29.187:50010
2021-10-29 13:24:34,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43128, dest: /172.31.29.187:50010, bytes: 4797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-152566958_227, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129, duration: 4340998
2021-10-29 13:24:34,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:24:34,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741954_1130 src: /172.31.16.191:52276 dest: /172.31.29.187:50010
2021-10-29 13:24:34,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52276, dest: /172.31.29.187:50010, bytes: 13730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_509195649_243, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741954_1130, duration: 12713761
2021-10-29 13:24:34,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741954_1130, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:24:36,902 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741942_1118 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741942 for deletion
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741943_1119 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741943 for deletion
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741944_1120 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741944 for deletion
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741945_1121 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741945 for deletion
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741942_1118 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741942
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741943_1119 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741943
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741944_1120 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741944
2021-10-29 13:24:36,903 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741945_1121 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741945
2021-10-29 13:24:38,280 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127
2021-10-29 13:26:13,481 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741941_1117
2021-10-29 13:26:18,483 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128
2021-10-29 13:26:18,483 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129
2021-10-29 13:32:45,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741955_1131 src: /172.31.29.187:43172 dest: /172.31.29.187:50010
2021-10-29 13:32:46,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43172, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1921002306_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741955_1131, duration: 1174694907
2021-10-29 13:32:46,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741955_1131, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:32:46,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741956_1132 src: /172.31.29.187:43176 dest: /172.31.29.187:50010
2021-10-29 13:32:47,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43176, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1921002306_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741956_1132, duration: 1175351389
2021-10-29 13:32:47,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741956_1132, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:32:47,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741957_1133 src: /172.31.29.187:43180 dest: /172.31.29.187:50010
2021-10-29 13:32:48,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43180, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1921002306_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741957_1133, duration: 1112339842
2021-10-29 13:32:48,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741957_1133, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:32:48,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741958_1134 src: /172.31.29.187:43184 dest: /172.31.29.187:50010
2021-10-29 13:32:50,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43184, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1921002306_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741958_1134, duration: 1161210423
2021-10-29 13:32:50,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741958_1134, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:32:50,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741959_1135 src: /172.31.29.187:43188 dest: /172.31.29.187:50010
2021-10-29 13:32:50,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43188, dest: /172.31.29.187:50010, bytes: 57442089, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1921002306_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741959_1135, duration: 512045974
2021-10-29 13:32:50,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741959_1135, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:33:09,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741936_1112 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741936 for deletion
2021-10-29 13:33:09,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741937_1113 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741937 for deletion
2021-10-29 13:33:09,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741938_1114 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741938 for deletion
2021-10-29 13:33:09,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741939_1115 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741939 for deletion
2021-10-29 13:33:09,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741940_1116 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741940 for deletion
2021-10-29 13:33:09,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741941_1117 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741941 for deletion
2021-10-29 13:33:09,931 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741936_1112 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741936
2021-10-29 13:33:09,931 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741937_1113 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741937
2021-10-29 13:33:09,931 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741938_1114 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741938
2021-10-29 13:33:09,931 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741939_1115 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741939
2021-10-29 13:33:09,933 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741940_1116 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741940
2021-10-29 13:33:09,933 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741941_1117 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741941
2021-10-29 13:33:24,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741960_1136 src: /172.31.29.187:43206 dest: /172.31.29.187:50010
2021-10-29 13:33:24,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43206, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1352452414_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741960_1136, duration: 28948472
2021-10-29 13:33:24,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741960_1136, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:33:24,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741961_1137 src: /172.31.29.187:43210 dest: /172.31.29.187:50010
2021-10-29 13:33:24,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43210, dest: /172.31.29.187:50010, bytes: 522, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1352452414_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741961_1137, duration: 6243572
2021-10-29 13:33:24,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741961_1137, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:33:25,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741962_1138 src: /172.31.29.187:43214 dest: /172.31.29.187:50010
2021-10-29 13:33:25,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43214, dest: /172.31.29.187:50010, bytes: 165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1352452414_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741962_1138, duration: 3142026
2021-10-29 13:33:25,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741962_1138, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:33:25,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741963_1139 src: /172.31.29.187:43218 dest: /172.31.29.187:50010
2021-10-29 13:33:25,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43218, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1352452414_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741963_1139, duration: 4220531
2021-10-29 13:33:25,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741963_1139, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:33:31,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741964_1140 src: /172.31.16.191:52320 dest: /172.31.29.187:50010
2021-10-29 13:33:31,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52320, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1166584222_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741964_1140, duration: 51234350
2021-10-29 13:33:31,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741964_1140, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:34:40,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741966_1142 src: /172.31.18.188:45848 dest: /172.31.29.187:50010
2021-10-29 13:34:44,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45848, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0009_r_000000_0_-1588855419_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741966_1142, duration: 3895381344
2021-10-29 13:34:44,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741966_1142, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:34:44,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741967_1143 src: /172.31.18.188:45852 dest: /172.31.29.187:50010
2021-10-29 13:34:47,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45852, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0009_r_000000_0_-1588855419_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741967_1143, duration: 3018187986
2021-10-29 13:34:47,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741967_1143, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:34:47,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741968_1144 src: /172.31.18.188:45856 dest: /172.31.29.187:50010
2021-10-29 13:34:50,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45856, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0009_r_000000_0_-1588855419_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741968_1144, duration: 3037858455
2021-10-29 13:34:50,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741968_1144, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:34:50,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741969_1145 src: /172.31.18.188:45860 dest: /172.31.29.187:50010
2021-10-29 13:34:53,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45860, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0009_r_000000_0_-1588855419_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741969_1145, duration: 3015290254
2021-10-29 13:34:53,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741969_1145, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:34:53,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741970_1146 src: /172.31.18.188:45864 dest: /172.31.29.187:50010
2021-10-29 13:34:55,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45864, dest: /172.31.29.187:50010, bytes: 67559239, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0009_r_000000_0_-1588855419_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741970_1146, duration: 1822358166
2021-10-29 13:34:55,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741970_1146, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:34:55,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741971_1147 src: /172.31.16.191:52384 dest: /172.31.29.187:50010
2021-10-29 13:34:55,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:52384, dest: /172.31.29.187:50010, bytes: 352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1166584222_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741971_1147, duration: 5611066
2021-10-29 13:34:55,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741971_1147, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:35:02,565 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741956_1132
2021-10-29 13:35:03,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741971_1147 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741971 for deletion
2021-10-29 13:35:03,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741960_1136 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741960 for deletion
2021-10-29 13:35:03,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741961_1137 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741961 for deletion
2021-10-29 13:35:03,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741962_1138 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741962 for deletion
2021-10-29 13:35:03,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741963_1139 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741963 for deletion
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741964_1140 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741964 for deletion
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741971_1147 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741971
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741960_1136 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741960
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741961_1137 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741961
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741962_1138 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741962
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741963_1139 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741963
2021-10-29 13:35:03,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741964_1140 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741964
2021-10-29 13:35:04,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152 src: /172.31.29.187:43280 dest: /172.31.29.187:50010
2021-10-29 13:35:04,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43280, dest: /172.31.29.187:50010, bytes: 15244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_745162832_259, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152, duration: 4682308
2021-10-29 13:35:04,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:37:16,369 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741968_1144
2021-10-29 13:39:03,948 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741955_1131 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741955 for deletion
2021-10-29 13:39:03,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741956_1132 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741956 for deletion
2021-10-29 13:39:03,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741957_1133 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741957 for deletion
2021-10-29 13:39:03,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741958_1134 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741958 for deletion
2021-10-29 13:39:03,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741959_1135 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741959 for deletion
2021-10-29 13:39:03,955 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741955_1131 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741955
2021-10-29 13:39:03,955 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741956_1132 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741956
2021-10-29 13:39:03,956 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741957_1133 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741957
2021-10-29 13:39:03,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741958_1134 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741958
2021-10-29 13:39:03,967 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741959_1135 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741959
2021-10-29 13:39:25,569 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741957_1133
2021-10-29 13:39:30,571 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152
2021-10-29 13:39:38,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153 src: /172.31.29.187:43312 dest: /172.31.29.187:50010
2021-10-29 13:39:39,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43312, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1626298554_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153, duration: 1167818885
2021-10-29 13:39:39,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:39:39,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741978_1154 src: /172.31.29.187:43316 dest: /172.31.29.187:50010
2021-10-29 13:39:40,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43316, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1626298554_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741978_1154, duration: 1192194804
2021-10-29 13:39:40,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741978_1154, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:39:40,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741979_1155 src: /172.31.29.187:43320 dest: /172.31.29.187:50010
2021-10-29 13:39:41,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43320, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1626298554_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741979_1155, duration: 1202917434
2021-10-29 13:39:41,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741979_1155, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:39:41,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156 src: /172.31.29.187:43324 dest: /172.31.29.187:50010
2021-10-29 13:39:42,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43324, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1626298554_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156, duration: 1089650820
2021-10-29 13:39:42,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:39:42,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157 src: /172.31.29.187:43328 dest: /172.31.29.187:50010
2021-10-29 13:39:43,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43328, dest: /172.31.29.187:50010, bytes: 57442089, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1626298554_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157, duration: 473696120
2021-10-29 13:39:43,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:39:57,950 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741968_1144 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741968 for deletion
2021-10-29 13:39:57,950 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741969_1145 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741969 for deletion
2021-10-29 13:39:57,950 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741970_1146 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741970 for deletion
2021-10-29 13:39:57,950 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741966_1142 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741966 for deletion
2021-10-29 13:39:57,951 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741967_1143 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741967 for deletion
2021-10-29 13:39:57,951 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741968_1144 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741968
2021-10-29 13:39:57,963 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741969_1145 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741969
2021-10-29 13:39:57,973 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741970_1146 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741970
2021-10-29 13:39:57,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741966_1142 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741966
2021-10-29 13:39:57,979 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741967_1143 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741967
2021-10-29 13:40:00,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741982_1158 src: /172.31.29.187:43338 dest: /172.31.29.187:50010
2021-10-29 13:40:00,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43338, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_954686232_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741982_1158, duration: 32009364
2021-10-29 13:40:00,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741982_1158, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:40:00,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741983_1159 src: /172.31.29.187:43342 dest: /172.31.29.187:50010
2021-10-29 13:40:00,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43342, dest: /172.31.29.187:50010, bytes: 482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_954686232_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741983_1159, duration: 7772958
2021-10-29 13:40:00,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741983_1159, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:40:00,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741984_1160 src: /172.31.29.187:43346 dest: /172.31.29.187:50010
2021-10-29 13:40:00,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43346, dest: /172.31.29.187:50010, bytes: 165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_954686232_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741984_1160, duration: 4249953
2021-10-29 13:40:00,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741984_1160, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:40:00,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741985_1161 src: /172.31.29.187:43350 dest: /172.31.29.187:50010
2021-10-29 13:40:00,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43350, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_954686232_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741985_1161, duration: 2694426
2021-10-29 13:40:00,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741985_1161, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:41:54,574 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153
2021-10-29 13:41:59,576 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741982_1158
2021-10-29 13:42:52,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164 src: /172.31.29.187:43408 dest: /172.31.29.187:50010
2021-10-29 13:43:00,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43408, dest: /172.31.29.187:50010, bytes: 58095353, op: HDFS_WRITE, cliID: DFSClient_attempt_1635512855558_0011_r_000000_0_1888262310_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164, duration: 8212943937
2021-10-29 13:43:00,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:43:00,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166 src: /172.31.18.188:45990 dest: /172.31.29.187:50010
2021-10-29 13:43:00,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45990, dest: /172.31.29.187:50010, bytes: 73026, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1108026298_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166, duration: 8943304
2021-10-29 13:43:00,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:43:00,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167 src: /172.31.18.188:45994 dest: /172.31.29.187:50010
2021-10-29 13:43:00,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:45994, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1108026298_1, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167, duration: 4062542
2021-10-29 13:43:00,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:43:08,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168 src: /172.31.18.188:46002 dest: /172.31.29.187:50010
2021-10-29 13:43:08,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:46002, dest: /172.31.29.187:50010, bytes: 168054, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1762453584_516, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168, duration: 4567015
2021-10-29 13:43:08,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-29 13:43:08,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170 src: /172.31.29.187:43426 dest: /172.31.29.187:50010
2021-10-29 13:43:08,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:43426, dest: /172.31.29.187:50010, bytes: 29033, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1833458286_303, offset: 0, srvID: 057955f0-64c4-4f1d-9a76-1f53690c49c6, blockid: BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170, duration: 5509094
2021-10-29 13:43:08,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-29 13:43:09,588 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166
2021-10-29 13:43:09,953 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741984_1160 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741984 for deletion
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741985_1161 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741985 for deletion
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741982_1158 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741982 for deletion
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741983_1159 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741983 for deletion
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741984_1160 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741984
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741985_1161 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741985
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741982_1158 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741982
2021-10-29 13:43:09,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-840138802-172.31.29.187-1635510950643 blk_1073741983_1159 file /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized/subdir0/subdir0/blk_1073741983
2021-10-29 13:43:14,590 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168
2021-10-29 14:07:10,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022 to 172.31.16.191:50010 
2021-10-29 14:07:10,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069 to 172.31.16.191:50010 
2021-10-29 14:07:10,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069 (numBytes=117038) to /172.31.16.191:50010
2021-10-29 14:07:10,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022 (numBytes=92201) to /172.31.16.191:50010
2021-10-29 14:07:11,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741975_1151 src: /172.31.16.191:52556 dest: /172.31.29.187:50010
2021-10-29 14:07:11,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741891_1067 src: /172.31.16.191:52558 dest: /172.31.29.187:50010
2021-10-29 14:07:11,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741975_1151 src: /172.31.16.191:52556 dest: /172.31.29.187:50010 of size 29776
2021-10-29 14:07:11,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741891_1067 src: /172.31.16.191:52558 dest: /172.31.29.187:50010 of size 91619
2021-10-29 14:07:13,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156 to 172.31.16.191:50010 
2021-10-29 14:07:13,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092 to 172.31.16.191:50010 
2021-10-29 14:07:13,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092 (numBytes=122609) to /172.31.16.191:50010
2021-10-29 14:07:14,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741993_1169 src: /172.31.16.191:52562 dest: /172.31.29.187:50010
2021-10-29 14:07:14,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741993_1169 src: /172.31.16.191:52562 dest: /172.31.29.187:50010 of size 26321
2021-10-29 14:07:14,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741915_1091 src: /172.31.16.191:52560 dest: /172.31.29.187:50010
2021-10-29 14:07:14,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741915_1091 src: /172.31.16.191:52560 dest: /172.31.29.187:50010 of size 105456
2021-10-29 14:07:15,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156 (numBytes=134217728) to /172.31.16.191:50010
2021-10-29 14:07:16,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164 to 172.31.16.191:50010 
2021-10-29 14:07:16,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166 to 172.31.16.191:50010 
2021-10-29 14:07:16,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166 (numBytes=73026) to /172.31.16.191:50010
2021-10-29 14:07:16,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164 (numBytes=58095353) to /172.31.16.191:50010
2021-10-29 14:07:17,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741844_1020 src: /172.31.16.191:52564 dest: /172.31.29.187:50010
2021-10-29 14:07:17,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741892_1068 src: /172.31.16.191:52566 dest: /172.31.29.187:50010
2021-10-29 14:07:17,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741844_1020 src: /172.31.16.191:52564 dest: /172.31.29.187:50010 of size 91625
2021-10-29 14:07:17,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741892_1068 src: /172.31.16.191:52566 dest: /172.31.29.187:50010 of size 105458
2021-10-29 14:07:19,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168 to 172.31.16.191:50010 
2021-10-29 14:07:19,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021 to 172.31.16.191:50010 
2021-10-29 14:07:19,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168 (numBytes=168054) to /172.31.16.191:50010
2021-10-29 14:07:19,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021 (numBytes=105454) to /172.31.16.191:50010
2021-10-29 14:07:19,840 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741915_1091
2021-10-29 14:07:19,840 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741891_1067
2021-10-29 14:07:20,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741870_1046 src: /172.31.16.191:52570 dest: /172.31.29.187:50010
2021-10-29 14:07:20,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741927_1103 src: /172.31.16.191:52568 dest: /172.31.29.187:50010
2021-10-29 14:07:20,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741870_1046 src: /172.31.16.191:52570 dest: /172.31.29.187:50010 of size 120373
2021-10-29 14:07:20,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741927_1103 src: /172.31.16.191:52568 dest: /172.31.29.187:50010 of size 33895
2021-10-29 14:07:22,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070 to 172.31.16.191:50010 
2021-10-29 14:07:22,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090 to 172.31.16.191:50010 
2021-10-29 14:07:22,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070 (numBytes=20480) to /172.31.16.191:50010
2021-10-29 14:07:22,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090 (numBytes=91581) to /172.31.16.191:50010
2021-10-29 14:07:23,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741917_1093 src: /172.31.16.191:52572 dest: /172.31.29.187:50010
2021-10-29 14:07:23,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741972_1148 src: /172.31.16.191:52574 dest: /172.31.29.187:50010
2021-10-29 14:07:23,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741917_1093 src: /172.31.16.191:52572 dest: /172.31.29.187:50010 of size 17110
2021-10-29 14:07:23,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741972_1148 src: /172.31.16.191:52574 dest: /172.31.29.187:50010 of size 72863
2021-10-29 14:07:24,842 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741892_1068
2021-10-29 14:07:24,843 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741844_1020
2021-10-29 14:07:25,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126 to 172.31.16.191:50010 
2021-10-29 14:07:25,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127 to 172.31.16.191:50010 
2021-10-29 14:07:25,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126 (numBytes=73188) to /172.31.16.191:50010
2021-10-29 14:07:25,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127 (numBytes=105128) to /172.31.16.191:50010
2021-10-29 14:07:26,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741974_1150 src: /172.31.16.191:52576 dest: /172.31.29.187:50010
2021-10-29 14:07:26,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741973_1149 src: /172.31.16.191:52578 dest: /172.31.29.187:50010
2021-10-29 14:07:26,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741974_1150 src: /172.31.16.191:52576 dest: /172.31.29.187:50010 of size 106612
2021-10-29 14:07:26,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741973_1149 src: /172.31.16.191:52578 dest: /172.31.29.187:50010 of size 105128
2021-10-29 14:07:28,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167 to 172.31.16.191:50010 
2021-10-29 14:07:28,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170 to 172.31.16.191:50010 
2021-10-29 14:07:28,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167 (numBytes=105128) to /172.31.16.191:50010
2021-10-29 14:07:28,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170 (numBytes=29033) to /172.31.16.191:50010
2021-10-29 14:07:29,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741871_1047 src: /172.31.16.191:52580 dest: /172.31.29.187:50010
2021-10-29 14:07:29,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-840138802-172.31.29.187-1635510950643:blk_1073741847_1023 src: /172.31.16.191:52582 dest: /172.31.29.187:50010
2021-10-29 14:07:29,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741847_1023 src: /172.31.16.191:52582 dest: /172.31.29.187:50010 of size 23845
2021-10-29 14:07:29,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-840138802-172.31.29.187-1635510950643:blk_1073741871_1047 src: /172.31.16.191:52580 dest: /172.31.29.187:50010 of size 17110
2021-10-29 14:07:29,846 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741927_1103
2021-10-29 14:07:29,846 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741972_1148
2021-10-29 14:07:31,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152 to 172.31.16.191:50010 
2021-10-29 14:07:31,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106 to 172.31.16.191:50010 
2021-10-29 14:07:31,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152 (numBytes=15244) to /172.31.16.191:50010
2021-10-29 14:07:31,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106 (numBytes=6189) to /172.31.16.191:50010
2021-10-29 14:07:34,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128 to 172.31.16.191:50010 
2021-10-29 14:07:34,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129 to 172.31.16.191:50010 
2021-10-29 14:07:34,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129 (numBytes=4797) to /172.31.16.191:50010
2021-10-29 14:07:34,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128 (numBytes=117253) to /172.31.16.191:50010
2021-10-29 14:07:34,848 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741871_1047
2021-10-29 14:07:34,848 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-840138802-172.31.29.187-1635510950643:blk_1073741974_1150
2021-10-29 14:07:37,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=057955f0-64c4-4f1d-9a76-1f53690c49c6, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-31d78924-11d9-4680-8b2c-4e9b5a00a3e6;nsid=199133153;c=0) Starting thread to transfer BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157 to 172.31.16.191:50010 
2021-10-29 14:07:40,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157 (numBytes=57442089) to /172.31.16.191:50010
2021-10-29 14:07:44,850 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Failed to read previous verification times.
java.io.FileNotFoundException: /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/dncp_block_verification.log.curr (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.openFile(RollingLogsImpl.java:179)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.readNext(RollingLogsImpl.java:192)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.<init>(RollingLogsImpl.java:146)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.<init>(RollingLogsImpl.java:136)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl.iterator(RollingLogsImpl.java:97)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl.iterator(RollingLogsImpl.java:36)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.assignInitialVerificationTimes(BlockPoolSliceScanner.java:546)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:645)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting CheckDiskError Thread
2021-10-29 14:07:44,853 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021
java.io.IOException: BlockId 1073741845 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,853 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021
java.io.IOException: BlockId 1073741845 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,853 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741845_1021
2021-10-29 14:07:44,861 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024
java.io.IOException: BlockId 1073741848 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,861 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024
java.io.IOException: BlockId 1073741848 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,861 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741848_1024
2021-10-29 14:07:44,862 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070
java.io.IOException: BlockId 1073741894 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,862 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070
java.io.IOException: BlockId 1073741894 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,862 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741894_1070
2021-10-29 14:07:44,863 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741978_1154
java.io.IOException: BlockId 1073741978 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,863 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741978_1154
java.io.IOException: BlockId 1073741978 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,863 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741978_1154
2021-10-29 14:07:44,864 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741928_1104
java.io.IOException: BlockId 1073741928 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,864 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741928_1104
java.io.IOException: BlockId 1073741928 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,864 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741928_1104
2021-10-29 14:07:44,866 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106
java.io.IOException: BlockId 1073741930 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,866 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106
java.io.IOException: BlockId 1073741930 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,866 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741930_1106
2021-10-29 14:07:44,867 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167
java.io.IOException: BlockId 1073741991 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,867 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167
java.io.IOException: BlockId 1073741991 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,867 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741991_1167
2021-10-29 14:07:44,868 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170
java.io.IOException: BlockId 1073741994 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,868 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170
java.io.IOException: BlockId 1073741994 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,868 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741994_1170
2021-10-29 14:07:44,869 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126
java.io.IOException: BlockId 1073741950 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,869 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126
java.io.IOException: BlockId 1073741950 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,869 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741950_1126
2021-10-29 14:07:44,872 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741954_1130
java.io.IOException: BlockId 1073741954 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,873 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741954_1130
java.io.IOException: BlockId 1073741954 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,873 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741954_1130
2021-10-29 14:07:44,874 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741975_1151
java.io.IOException: BlockId 1073741975 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,874 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741975_1151
java.io.IOException: BlockId 1073741975 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,874 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741975_1151
2021-10-29 14:07:44,879 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741917_1093
java.io.IOException: BlockId 1073741917 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,879 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741917_1093
java.io.IOException: BlockId 1073741917 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,879 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741917_1093
2021-10-29 14:07:44,881 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741973_1149
java.io.IOException: BlockId 1073741973 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,882 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741973_1149
java.io.IOException: BlockId 1073741973 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,883 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741973_1149
2021-10-29 14:07:44,885 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741979_1155
java.io.IOException: BlockId 1073741979 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,885 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741979_1155
java.io.IOException: BlockId 1073741979 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,886 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741979_1155
2021-10-29 14:07:44,886 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164
java.io.IOException: BlockId 1073741988 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,886 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164
java.io.IOException: BlockId 1073741988 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,887 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741988_1164
2021-10-29 14:07:44,887 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045
java.io.IOException: BlockId 1073741869 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,887 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045
java.io.IOException: BlockId 1073741869 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,887 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741869_1045
2021-10-29 14:07:44,888 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741993_1169
java.io.IOException: BlockId 1073741993 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,888 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741993_1169
java.io.IOException: BlockId 1073741993 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,888 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741993_1169
2021-10-29 14:07:44,890 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022
java.io.IOException: BlockId 1073741846 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,890 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022
java.io.IOException: BlockId 1073741846 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,890 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741846_1022
2021-10-29 14:07:44,890 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044
java.io.IOException: BlockId 1073741868 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,891 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044
java.io.IOException: BlockId 1073741868 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,891 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741868_1044
2021-10-29 14:07:44,891 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741870_1046
java.io.IOException: BlockId 1073741870 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,892 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741870_1046
java.io.IOException: BlockId 1073741870 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,892 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741870_1046
2021-10-29 14:07:44,893 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741847_1023
java.io.IOException: BlockId 1073741847 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,893 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741847_1023
java.io.IOException: BlockId 1073741847 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,893 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741847_1023
2021-10-29 14:07:44,896 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069
java.io.IOException: BlockId 1073741893 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,896 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069
java.io.IOException: BlockId 1073741893 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,896 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741893_1069
2021-10-29 14:07:44,897 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090
java.io.IOException: BlockId 1073741914 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,897 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090
java.io.IOException: BlockId 1073741914 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,897 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741914_1090
2021-10-29 14:07:44,897 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092
java.io.IOException: BlockId 1073741916 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,898 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092
java.io.IOException: BlockId 1073741916 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,898 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741916_1092
2021-10-29 14:07:44,899 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156
java.io.IOException: BlockId 1073741980 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,899 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156
java.io.IOException: BlockId 1073741980 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,899 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741980_1156
2021-10-29 14:07:44,899 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105
java.io.IOException: BlockId 1073741929 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,900 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105
java.io.IOException: BlockId 1073741929 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,900 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741929_1105
2021-10-29 14:07:44,900 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: BP-840138802-172.31.29.187-1635510950643:blk_1073741935_1111 is no longer in the dataset
2021-10-29 14:07:44,900 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127
java.io.IOException: BlockId 1073741951 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,901 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127
java.io.IOException: BlockId 1073741951 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,901 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741951_1127
2021-10-29 14:07:44,902 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128
java.io.IOException: BlockId 1073741952 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,902 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128
java.io.IOException: BlockId 1073741952 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,902 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741952_1128
2021-10-29 14:07:44,903 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129
java.io.IOException: BlockId 1073741953 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,903 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129
java.io.IOException: BlockId 1073741953 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,903 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741953_1129
2021-10-29 14:07:44,904 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157
java.io.IOException: BlockId 1073741981 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,904 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157
java.io.IOException: BlockId 1073741981 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,904 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741981_1157
2021-10-29 14:07:44,905 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: BP-840138802-172.31.29.187-1635510950643:blk_1073741957_1133 is no longer in the dataset
2021-10-29 14:07:44,905 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152
java.io.IOException: BlockId 1073741976 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,905 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152
java.io.IOException: BlockId 1073741976 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,905 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741976_1152
2021-10-29 14:07:44,906 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153
java.io.IOException: BlockId 1073741977 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,906 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153
java.io.IOException: BlockId 1073741977 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,906 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741977_1153
2021-10-29 14:07:44,907 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166
java.io.IOException: BlockId 1073741990 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,907 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166
java.io.IOException: BlockId 1073741990 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,907 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741990_1166
2021-10-29 14:07:44,914 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168
java.io.IOException: BlockId 1073741992 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,919 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168
java.io.IOException: BlockId 1073741992 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,919 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741992_1168
2021-10-29 14:07:44,920 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741891_1067
java.io.IOException: BlockId 1073741891 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,920 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741891_1067
java.io.IOException: BlockId 1073741891 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,920 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741891_1067
2021-10-29 14:07:44,921 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741915_1091
java.io.IOException: BlockId 1073741915 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,921 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741915_1091
java.io.IOException: BlockId 1073741915 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,921 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741915_1091
2021-10-29 14:07:44,925 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741844_1020
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,925 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741844_1020
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,926 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741844_1020
2021-10-29 14:07:44,926 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741892_1068
java.io.IOException: BlockId 1073741892 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,926 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741892_1068
java.io.IOException: BlockId 1073741892 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,927 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741892_1068
2021-10-29 14:07:44,927 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741927_1103
java.io.IOException: BlockId 1073741927 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,927 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741927_1103
java.io.IOException: BlockId 1073741927 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,927 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741927_1103
2021-10-29 14:07:44,928 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741972_1148
java.io.IOException: BlockId 1073741972 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,928 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741972_1148
java.io.IOException: BlockId 1073741972 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,928 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741972_1148
2021-10-29 14:07:44,929 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741871_1047
java.io.IOException: BlockId 1073741871 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,929 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741871_1047
java.io.IOException: BlockId 1073741871 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,929 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741871_1047
2021-10-29 14:07:44,930 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741974_1150
java.io.IOException: BlockId 1073741974 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,930 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-840138802-172.31.29.187-1635510950643:blk_1073741974_1150
java.io.IOException: BlockId 1073741974 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:07:44,930 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-840138802-172.31.29.187-1635510950643:blk_1073741974_1150
2021-10-29 14:07:44,931 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Received exception: 
java.io.IOException: Failed to rename /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/dncp_block_verification.log.curr to /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/dncp_block_verification.log.prev
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl.roll(RollingLogsImpl.java:120)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.rollVerificationLogs(BlockPoolSliceScanner.java:716)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:697)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:27:24,793 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:27:25,086 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:37:24,796 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:37:25,117 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:47:24,800 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:47:25,149 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:57:24,802 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 14:57:25,180 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:07:24,807 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:07:25,212 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:17:24,810 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:17:25,241 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:27:24,813 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:27:25,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:37:24,816 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:37:25,299 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:47:24,820 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:47:25,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:57:24,823 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 15:57:25,365 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:07:24,826 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:07:25,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:13:19,772 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Exception occured while compiling report: 
java.io.IOException: Invalid directory or I/O error occurred for dir: /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/finalized
	at org.apache.hadoop.fs.FileUtil.listFiles(FileUtil.java:1164)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:610)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:600)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:585)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:13:19,776 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-840138802-172.31.29.187-1635510950643 Total blocks: 0, missing metadata files:42, missing block files:42, missing blocks in memory:0, mismatched blocks:0
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741844 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741845 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741846 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741847 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741848 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741868 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741869 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741870 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741871 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741891 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741892 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741893 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741894 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741914 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741915 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741916 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741917 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741927 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741928 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741929 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741930 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741950 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741951 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741952 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741953 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741954 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741972 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741973 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741974 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741975 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741976 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741977 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741978 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741979 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741980 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741981 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741988 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741990 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741991 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741992 from memory with missing block file on the disk
2021-10-29 16:13:19,776 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741993 from memory with missing block file on the disk
2021-10-29 16:13:19,777 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741994 from memory with missing block file on the disk
2021-10-29 16:17:24,829 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:17:25,429 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:27:24,834 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:27:25,462 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:37:24,837 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:37:25,495 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:47:24,840 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:47:25,527 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:51:07,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe061820b9d2,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-29 16:51:07,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-840138802-172.31.29.187-1635510950643
2021-10-29 16:57:24,843 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 16:57:25,558 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:07:24,847 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:07:25,590 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:17:24,850 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:17:25,629 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:27:24,852 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:27:25,657 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:37:24,855 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:37:25,694 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:47:24,858 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:47:25,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:57:24,861 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 17:57:25,759 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 18:07:24,864 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 18:07:25,791 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 18:17:24,867 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 18:17:25,824 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-10-29 18:20:45,879 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-29 18:20:45,916 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Failed to write dfsUsed to /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/dfsUsed
java.io.FileNotFoundException: /tmp/hadoop-ubuntu/dfs/data/current/BP-840138802-172.31.29.187-1635510950643/current/dfsUsed (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at java.io.FileWriter.<init>(FileWriter.java:90)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed(BlockPoolSlice.java:236)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice$1.run(BlockPoolSlice.java:144)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2021-10-29 18:20:45,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 06:14:14,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 06:14:14,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 06:14:14,912 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 06:14:14,999 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 06:14:14,999 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 06:14:15,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 06:14:15,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 06:14:15,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 06:14:15,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 06:14:15,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 06:14:15,090 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 06:14:15,093 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 06:14:15,101 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 06:14:15,103 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 06:14:15,103 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 06:14:15,103 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 06:14:15,115 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 06:14:15,117 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 06:14:15,117 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 06:14:15,266 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 06:14:15,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 06:14:15,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 06:14:15,358 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 06:14:15,371 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 06:14:15,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 06:14:15,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 06:14:15,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 06:14:15,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 06:14:15,454 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 06:14:15,455 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 06:14:16,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:17,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:18,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:19,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:20,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:21,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:22,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:23,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:24,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:25,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:25,568 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-10-30 06:14:31,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:32,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:33,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:34,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:35,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:36,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:37,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:38,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:39,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:40,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:40,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-10-30 06:14:46,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:47,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:48,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:49,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:50,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:51,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:52,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:53,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:54,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-30 06:14:54,915 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-30 06:14:54,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 06:15:56,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 06:15:56,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 06:15:56,656 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 06:15:56,746 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 06:15:56,746 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 06:15:56,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 06:15:56,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 06:15:56,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 06:15:56,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 06:15:56,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 06:15:56,830 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 06:15:56,833 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 06:15:56,841 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 06:15:56,843 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 06:15:56,843 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 06:15:56,843 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 06:15:56,854 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 06:15:56,856 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 06:15:56,856 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 06:15:57,003 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 06:15:57,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 06:15:57,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 06:15:57,061 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 06:15:57,074 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 06:15:57,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 06:15:57,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 06:15:57,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 06:15:57,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 06:15:57,146 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 06:15:57,147 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 06:15:57,393 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 3715@hadoopmaster
2021-10-30 06:15:57,394 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,394 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 06:15:57,464 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,464 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,464 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209 is not formatted for BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,464 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 06:15:57,464 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-534447240-172.31.29.187-1635574545209 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current
2021-10-30 06:15:57,467 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-30 06:15:57,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=9275432;bpid=BP-534447240-172.31.29.187-1635574545209;lv=-56;nsInfo=lv=-60;cid=CID-6221382c-9263-4403-baed-12ad0f0df2b1;nsid=9275432;c=0;bpid=BP-534447240-172.31.29.187-1635574545209;dnuuid=null
2021-10-30 06:15:57,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID cae8ed5c-b8a1-4b15-aac0-fd3354627a04
2021-10-30 06:15:57,503 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-30 06:15:57,503 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-30 06:15:57,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-30 06:15:57,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,515 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-534447240-172.31.29.187-1635574545209 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 06:15:57,525 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-534447240-172.31.29.187-1635574545209 on /tmp/hadoop-ubuntu/dfs/data/current: 11ms
2021-10-30 06:15:57,525 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-534447240-172.31.29.187-1635574545209: 18ms
2021-10-30 06:15:57,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-534447240-172.31.29.187-1635574545209 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 06:15:57,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-534447240-172.31.29.187-1635574545209 on volume /tmp/hadoop-ubuntu/dfs/data/current: 0ms
2021-10-30 06:15:57,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-10-30 06:15:57,529 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635590909528 with interval 21600000
2021-10-30 06:15:57,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-534447240-172.31.29.187-1635574545209 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-30 06:15:57,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-534447240-172.31.29.187-1635574545209 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-30 06:15:57,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-30 06:15:57,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-534447240-172.31.29.187-1635574545209 (Datanode Uuid cae8ed5c-b8a1-4b15-aac0-fd3354627a04) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-30 06:15:57,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-534447240-172.31.29.187-1635574545209 (Datanode Uuid cae8ed5c-b8a1-4b15-aac0-fd3354627a04) service to hadoopmaster/172.31.29.187:8020
2021-10-30 06:15:57,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e4e7f8c52,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-30 06:15:57,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,734 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-30 06:15:57,734 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-30 06:15:57,735 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-30 06:15:57,735 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-30 06:15:57,735 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-534447240-172.31.29.187-1635574545209
2021-10-30 06:15:57,738 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-534447240-172.31.29.187-1635574545209 to blockPoolScannerMap, new size=1
2021-10-30 06:16:39,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741825_1001 src: /172.31.29.187:47462 dest: /172.31.29.187:50010
2021-10-30 06:16:40,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47462, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1813668866_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741825_1001, duration: 1095888488
2021-10-30 06:16:40,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:16:40,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741826_1002 src: /172.31.29.187:47464 dest: /172.31.29.187:50010
2021-10-30 06:16:42,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47464, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1813668866_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741826_1002, duration: 2061850953
2021-10-30 06:16:42,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:16:42,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741827_1003 src: /172.31.29.187:47466 dest: /172.31.29.187:50010
2021-10-30 06:16:44,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47466, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1813668866_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741827_1003, duration: 2065449603
2021-10-30 06:16:44,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:16:44,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741828_1004 src: /172.31.29.187:47468 dest: /172.31.29.187:50010
2021-10-30 06:16:46,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47468, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1813668866_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741828_1004, duration: 2083587582
2021-10-30 06:16:46,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:16:46,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741829_1005 src: /172.31.29.187:47470 dest: /172.31.29.187:50010
2021-10-30 06:16:47,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47470, dest: /172.31.29.187:50010, bytes: 57442089, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1813668866_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741829_1005, duration: 890990999
2021-10-30 06:16:47,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:18:07,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741830_1006 src: /172.31.29.187:47494 dest: /172.31.29.187:50010
2021-10-30 06:18:07,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47494, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2147280143_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741830_1006, duration: 27367281
2021-10-30 06:18:07,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:18:07,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741831_1007 src: /172.31.29.187:47496 dest: /172.31.29.187:50010
2021-10-30 06:18:07,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47496, dest: /172.31.29.187:50010, bytes: 482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2147280143_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741831_1007, duration: 1314196
2021-10-30 06:18:07,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:18:07,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741832_1008 src: /172.31.29.187:47498 dest: /172.31.29.187:50010
2021-10-30 06:18:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47498, dest: /172.31.29.187:50010, bytes: 115, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2147280143_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741832_1008, duration: 1631576
2021-10-30 06:18:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:18:07,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741833_1009 src: /172.31.29.187:47500 dest: /172.31.29.187:50010
2021-10-30 06:18:07,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47500, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2147280143_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741833_1009, duration: 1884993
2021-10-30 06:18:07,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:18:13,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741834_1010 src: /172.31.29.187:47520 dest: /172.31.29.187:50010
2021-10-30 06:18:13,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47520, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1746040999_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741834_1010, duration: 18088695
2021-10-30 06:18:13,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:18:55,040 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-534447240-172.31.29.187-1635574545209:blk_1073741826_1002
2021-10-30 06:19:23,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741835_1011 src: /172.31.29.187:47592 dest: /172.31.29.187:50010
2021-10-30 06:20:37,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741836_1012 src: /172.31.29.187:47650 dest: /172.31.29.187:50010
2021-10-30 06:20:45,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47650, dest: /172.31.29.187:50010, bytes: 58095353, op: HDFS_WRITE, cliID: DFSClient_attempt_1635574568112_0001_r_000000_0_1035190448_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741836_1012, duration: 7808830163
2021-10-30 06:20:45,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:20:45,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47592, dest: /172.31.29.187:50010, bytes: 66889, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1746040999_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741835_1011, duration: 82478693839
2021-10-30 06:20:45,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:20:45,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741837_1013 src: /172.31.29.187:47654 dest: /172.31.29.187:50010
2021-10-30 06:20:45,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47654, dest: /172.31.29.187:50010, bytes: 352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1746040999_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741837_1013, duration: 1211334
2021-10-30 06:20:45,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:20:45,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741838_1014 src: /172.31.29.187:47658 dest: /172.31.29.187:50010
2021-10-30 06:20:45,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47658, dest: /172.31.29.187:50010, bytes: 66889, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1746040999_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741838_1014, duration: 1441935
2021-10-30 06:20:45,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:20:45,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741839_1015 src: /172.31.29.187:47660 dest: /172.31.29.187:50010
2021-10-30 06:20:45,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47660, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1746040999_1, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741839_1015, duration: 1829536
2021-10-30 06:20:45,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:20:48,648 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2021-10-30 06:20:48,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2021-10-30 06:20:48,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2021-10-30 06:20:48,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-30 06:20:48,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2021-10-30 06:20:48,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2021-10-30 06:20:48,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741830
2021-10-30 06:20:48,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741831_1007 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741831
2021-10-30 06:20:48,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741832_1008 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741832
2021-10-30 06:20:48,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-30 06:20:48,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741834_1010 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741834
2021-10-30 06:20:48,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741835_1011 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741835
2021-10-30 06:20:52,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-534447240-172.31.29.187-1635574545209:blk_1073741840_1016 src: /172.31.29.187:47668 dest: /172.31.29.187:50010
2021-10-30 06:20:52,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47668, dest: /172.31.29.187:50010, bytes: 188110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1882558579_91, offset: 0, srvID: cae8ed5c-b8a1-4b15-aac0-fd3354627a04, blockid: BP-534447240-172.31.29.187-1635574545209:blk_1073741840_1016, duration: 17933586
2021-10-30 06:20:52,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-534447240-172.31.29.187-1635574545209:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 06:23:15,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2021-10-30 06:23:15,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-534447240-172.31.29.187-1635574545209 blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-534447240-172.31.29.187-1635574545209/current/finalized/subdir0/subdir0/blk_1073741837
2021-10-30 06:26:44,431 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-30 06:26:44,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 06:30:04,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 06:30:04,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 06:30:04,731 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 06:30:04,822 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 06:30:04,822 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 06:30:04,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 06:30:04,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 06:30:04,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 06:30:04,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 06:30:04,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 06:30:04,907 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 06:30:04,911 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 06:30:04,919 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 06:30:04,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 06:30:04,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 06:30:04,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 06:30:04,933 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 06:30:04,935 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 06:30:04,935 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 06:30:05,096 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 06:30:05,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 06:30:05,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 06:30:05,182 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 06:30:05,196 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 06:30:05,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 06:30:05,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 06:30:05,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 06:30:05,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 06:30:05,276 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 06:30:05,285 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 06:30:05,609 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 1623@hadoopmaster
2021-10-30 06:30:05,610 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,610 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 06:30:05,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-1545903507-172.31.29.187-1635575394105 is not formatted for BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 06:30:05,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1545903507-172.31.29.187-1635575394105 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-1545903507-172.31.29.187-1635575394105/current
2021-10-30 06:30:05,681 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-30 06:30:05,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1885071239;bpid=BP-1545903507-172.31.29.187-1635575394105;lv=-56;nsInfo=lv=-60;cid=CID-12ac914f-8873-46ed-abbb-cab00cf4839f;nsid=1885071239;c=0;bpid=BP-1545903507-172.31.29.187-1635575394105;dnuuid=null
2021-10-30 06:30:05,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4
2021-10-30 06:30:05,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-30 06:30:05,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-30 06:30:05,724 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-30 06:30:05,724 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1545903507-172.31.29.187-1635575394105 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 06:30:05,738 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1545903507-172.31.29.187-1635575394105 on /tmp/hadoop-ubuntu/dfs/data/current: 12ms
2021-10-30 06:30:05,738 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1545903507-172.31.29.187-1635575394105: 14ms
2021-10-30 06:30:05,739 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1545903507-172.31.29.187-1635575394105 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 06:30:05,739 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1545903507-172.31.29.187-1635575394105 on volume /tmp/hadoop-ubuntu/dfs/data/current: 0ms
2021-10-30 06:30:05,739 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-10-30 06:30:05,742 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635595383742 with interval 21600000
2021-10-30 06:30:05,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1545903507-172.31.29.187-1635575394105 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-30 06:30:05,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1545903507-172.31.29.187-1635575394105 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-30 06:30:05,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-30 06:30:05,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1545903507-172.31.29.187-1635575394105 (Datanode Uuid c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-30 06:30:05,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1545903507-172.31.29.187-1635575394105 (Datanode Uuid c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4) service to hadoopmaster/172.31.29.187:8020
2021-10-30 06:30:05,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x19c83ee8e8,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 63 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-30 06:30:05,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,982 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-30 06:30:05,982 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-30 06:30:05,983 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-30 06:30:05,983 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-30 06:30:05,983 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-1545903507-172.31.29.187-1635575394105
2021-10-30 06:30:05,987 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-1545903507-172.31.29.187-1635575394105 to blockPoolScannerMap, new size=1
2021-10-30 06:30:36,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741825_1001 src: /172.31.29.187:35900 dest: /172.31.29.187:50010
2021-10-30 06:30:38,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35900, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1841996631_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741825_1001, duration: 1651743553
2021-10-30 06:30:38,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:30:38,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741826_1002 src: /172.31.29.187:35906 dest: /172.31.29.187:50010
2021-10-30 06:30:39,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35906, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1841996631_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741826_1002, duration: 1711325067
2021-10-30 06:30:39,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:30:39,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741827_1003 src: /172.31.29.187:35910 dest: /172.31.29.187:50010
2021-10-30 06:30:41,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35910, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1841996631_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741827_1003, duration: 1873516968
2021-10-30 06:30:41,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:30:41,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741828_1004 src: /172.31.29.187:35914 dest: /172.31.29.187:50010
2021-10-30 06:30:43,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35914, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1841996631_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741828_1004, duration: 2085627743
2021-10-30 06:30:43,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:30:43,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741829_1005 src: /172.31.29.187:35918 dest: /172.31.29.187:50010
2021-10-30 06:30:44,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35918, dest: /172.31.29.187:50010, bytes: 57442089, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1841996631_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741829_1005, duration: 869158382
2021-10-30 06:30:44,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:31:45,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741830_1006 src: /172.31.29.187:35932 dest: /172.31.29.187:50010
2021-10-30 06:31:45,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35932, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763901969_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741830_1006, duration: 75941987
2021-10-30 06:31:45,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:31:45,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741831_1007 src: /172.31.29.187:35936 dest: /172.31.29.187:50010
2021-10-30 06:31:45,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35936, dest: /172.31.29.187:50010, bytes: 482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763901969_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741831_1007, duration: 11780098
2021-10-30 06:31:45,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:31:45,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741832_1008 src: /172.31.29.187:35940 dest: /172.31.29.187:50010
2021-10-30 06:31:45,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35940, dest: /172.31.29.187:50010, bytes: 165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763901969_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741832_1008, duration: 11650028
2021-10-30 06:31:45,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:31:45,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1545903507-172.31.29.187-1635575394105:blk_1073741833_1009 src: /172.31.29.187:35944 dest: /172.31.29.187:50010
2021-10-30 06:31:45,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:35944, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763901969_1, offset: 0, srvID: c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, blockid: BP-1545903507-172.31.29.187-1635575394105:blk_1073741833_1009, duration: 10862501
2021-10-30 06:31:45,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1545903507-172.31.29.187-1635575394105:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 06:31:47,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=c2c7b4fb-7ddd-48fb-a09d-cf9f768dc2d4, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-12ac914f-8873-46ed-abbb-cab00cf4839f;nsid=1885071239;c=0) Starting thread to transfer BP-1545903507-172.31.29.187-1635575394105:blk_1073741830_1006 to 172.31.18.188:50010 
2021-10-30 06:31:47,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-1545903507-172.31.29.187-1635575394105:blk_1073741830_1006 (numBytes=270356) to /172.31.18.188:50010
2021-10-30 06:32:44,694 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-30 06:32:44,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 13:34:11,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 13:34:11,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 13:34:11,914 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 13:34:12,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 13:34:12,002 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 13:34:12,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 13:34:12,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 13:34:12,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 13:34:12,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 13:34:12,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 13:34:12,087 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 13:34:12,090 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 13:34:12,098 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 13:34:12,100 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 13:34:12,100 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 13:34:12,100 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 13:34:12,112 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 13:34:12,114 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 13:34:12,114 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 13:34:12,292 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 13:34:12,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 13:34:12,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 13:34:12,357 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 13:34:12,372 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 13:34:12,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 13:34:12,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 13:34:12,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 13:34:12,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 13:34:12,452 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 13:34:12,454 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 13:34:12,739 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 1654@hadoopmaster
2021-10-30 13:34:12,740 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:12,740 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 13:34:12,792 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:12,792 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:12,792 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192 is not formatted for BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:12,792 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 13:34:12,792 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-6275426-172.31.29.187-1635600829192 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current
2021-10-30 13:34:12,795 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-30 13:34:12,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1733090601;bpid=BP-6275426-172.31.29.187-1635600829192;lv=-56;nsInfo=lv=-60;cid=CID-e06bff12-4e43-4d93-b92e-7459e74d1c6a;nsid=1733090601;c=0;bpid=BP-6275426-172.31.29.187-1635600829192;dnuuid=null
2021-10-30 13:34:12,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID ac93b48f-430d-4f92-b2f5-2fa5a6376df1
2021-10-30 13:34:12,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-30 13:34:12,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-30 13:34:12,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-30 13:34:12,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:12,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-6275426-172.31.29.187-1635600829192 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 13:34:12,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-6275426-172.31.29.187-1635600829192 on /tmp/hadoop-ubuntu/dfs/data/current: 11ms
2021-10-30 13:34:12,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-6275426-172.31.29.187-1635600829192: 12ms
2021-10-30 13:34:12,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-6275426-172.31.29.187-1635600829192 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 13:34:12,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-6275426-172.31.29.187-1635600829192 on volume /tmp/hadoop-ubuntu/dfs/data/current: 1ms
2021-10-30 13:34:12,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-10-30 13:34:12,849 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635612673849 with interval 21600000
2021-10-30 13:34:12,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-6275426-172.31.29.187-1635600829192 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-30 13:34:12,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-6275426-172.31.29.187-1635600829192 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-30 13:34:12,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-30 13:34:13,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-6275426-172.31.29.187-1635600829192 (Datanode Uuid ac93b48f-430d-4f92-b2f5-2fa5a6376df1) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-30 13:34:13,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-6275426-172.31.29.187-1635600829192 (Datanode Uuid ac93b48f-430d-4f92-b2f5-2fa5a6376df1) service to hadoopmaster/172.31.29.187:8020
2021-10-30 13:34:13,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x471700c615,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-30 13:34:13,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:13,054 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-30 13:34:13,054 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-30 13:34:13,055 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-30 13:34:13,055 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-30 13:34:13,056 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-6275426-172.31.29.187-1635600829192
2021-10-30 13:34:13,059 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-6275426-172.31.29.187-1635600829192 to blockPoolScannerMap, new size=1
2021-10-30 13:34:52,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741825_1001 src: /172.31.29.187:53124 dest: /172.31.29.187:50010
2021-10-30 13:34:53,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53124, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1703820813_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741825_1001, duration: 1609394168
2021-10-30 13:34:53,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:34:53,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741826_1002 src: /172.31.29.187:53128 dest: /172.31.29.187:50010
2021-10-30 13:34:55,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53128, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1703820813_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741826_1002, duration: 1464224851
2021-10-30 13:34:55,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:34:55,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741827_1003 src: /172.31.29.187:53132 dest: /172.31.29.187:50010
2021-10-30 13:34:57,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53132, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1703820813_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741827_1003, duration: 2043931001
2021-10-30 13:34:57,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:34:57,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741828_1004 src: /172.31.29.187:53136 dest: /172.31.29.187:50010
2021-10-30 13:34:59,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53136, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1703820813_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741828_1004, duration: 2087704739
2021-10-30 13:34:59,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:34:59,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741829_1005 src: /172.31.29.187:53140 dest: /172.31.29.187:50010
2021-10-30 13:35:00,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53140, dest: /172.31.29.187:50010, bytes: 57442089, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1703820813_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741829_1005, duration: 874721659
2021-10-30 13:35:00,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:35:20,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741830_1006 src: /172.31.29.187:53152 dest: /172.31.29.187:50010
2021-10-30 13:35:20,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53152, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_327556578_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741830_1006, duration: 34255427
2021-10-30 13:35:20,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:35:20,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741831_1007 src: /172.31.29.187:53156 dest: /172.31.29.187:50010
2021-10-30 13:35:20,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53156, dest: /172.31.29.187:50010, bytes: 482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_327556578_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741831_1007, duration: 13500233
2021-10-30 13:35:20,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:35:20,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741832_1008 src: /172.31.29.187:53160 dest: /172.31.29.187:50010
2021-10-30 13:35:20,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53160, dest: /172.31.29.187:50010, bytes: 165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_327556578_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741832_1008, duration: 8158205
2021-10-30 13:35:20,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:35:20,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741833_1009 src: /172.31.29.187:53164 dest: /172.31.29.187:50010
2021-10-30 13:35:20,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53164, dest: /172.31.29.187:50010, bytes: 88366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_327556578_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741833_1009, duration: 4693636
2021-10-30 13:35:20,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:35:24,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=ac93b48f-430d-4f92-b2f5-2fa5a6376df1, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-e06bff12-4e43-4d93-b92e-7459e74d1c6a;nsid=1733090601;c=0) Starting thread to transfer BP-6275426-172.31.29.187-1635600829192:blk_1073741830_1006 to 172.31.16.191:50010 
2021-10-30 13:35:24,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-6275426-172.31.29.187-1635600829192:blk_1073741830_1006 (numBytes=270356) to /172.31.16.191:50010
2021-10-30 13:35:26,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741834_1010 src: /172.31.29.187:53190 dest: /172.31.29.187:50010
2021-10-30 13:35:26,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53190, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_284220411_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741834_1010, duration: 39699047
2021-10-30 13:35:26,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:36:39,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741835_1011 src: /172.31.29.187:53262 dest: /172.31.29.187:50010
2021-10-30 13:37:10,276 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741826_1002
2021-10-30 13:37:45,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53262, dest: /172.31.29.187:50010, bytes: 73021, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_284220411_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741835_1011, duration: 65601455901
2021-10-30 13:37:45,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:37:45,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741837_1013 src: /172.31.29.187:53308 dest: /172.31.29.187:50010
2021-10-30 13:37:45,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53308, dest: /172.31.29.187:50010, bytes: 352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_284220411_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741837_1013, duration: 11985317
2021-10-30 13:37:45,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:37:45,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741838_1014 src: /172.31.29.187:53314 dest: /172.31.29.187:50010
2021-10-30 13:37:45,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53314, dest: /172.31.29.187:50010, bytes: 73021, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_284220411_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741838_1014, duration: 12179042
2021-10-30 13:37:45,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:37:45,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741839_1015 src: /172.31.29.187:53318 dest: /172.31.29.187:50010
2021-10-30 13:37:45,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53318, dest: /172.31.29.187:50010, bytes: 105128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_284220411_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741839_1015, duration: 11424991
2021-10-30 13:37:45,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:37:52,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741840_1016 src: /172.31.29.187:53328 dest: /172.31.29.187:50010
2021-10-30 13:37:52,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53328, dest: /172.31.29.187:50010, bytes: 171933, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-855782878_79, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741840_1016, duration: 24850592
2021-10-30 13:37:52,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:37:54,951 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2021-10-30 13:37:54,953 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2021-10-30 13:37:54,953 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2021-10-30 13:37:54,953 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-30 13:37:54,953 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2021-10-30 13:37:54,953 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2021-10-30 13:37:54,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741830
2021-10-30 13:37:54,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741831_1007 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741831
2021-10-30 13:37:54,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741832_1008 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741832
2021-10-30 13:37:54,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-30 13:37:54,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741834_1010 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741834
2021-10-30 13:37:54,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741835_1011 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741835
2021-10-30 13:38:06,950 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2021-10-30 13:38:06,950 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741837
2021-10-30 13:39:19,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741843_1019 src: /172.31.29.187:53344 dest: /172.31.29.187:50010
2021-10-30 13:39:20,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53344, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741843_1019, duration: 1268156802
2021-10-30 13:39:20,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:20,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741844_1020 src: /172.31.29.187:53348 dest: /172.31.29.187:50010
2021-10-30 13:39:22,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53348, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741844_1020, duration: 1884628033
2021-10-30 13:39:22,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:22,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741845_1021 src: /172.31.29.187:53352 dest: /172.31.29.187:50010
2021-10-30 13:39:24,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53352, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741845_1021, duration: 2085969191
2021-10-30 13:39:24,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:24,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741846_1022 src: /172.31.29.187:53356 dest: /172.31.29.187:50010
2021-10-30 13:39:26,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53356, dest: /172.31.29.187:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741846_1022, duration: 2097040676
2021-10-30 13:39:26,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:26,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741847_1023 src: /172.31.29.187:53360 dest: /172.31.29.187:50010
2021-10-30 13:39:27,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53360, dest: /172.31.29.187:50010, bytes: 57442089, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741847_1023, duration: 630582527
2021-10-30 13:39:27,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:27,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741848_1024 src: /172.31.29.187:53364 dest: /172.31.29.187:50010
2021-10-30 13:39:27,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53364, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741848_1024, duration: 13946919
2021-10-30 13:39:27,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:27,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741849_1025 src: /172.31.29.187:53368 dest: /172.31.29.187:50010
2021-10-30 13:39:27,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53368, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741849_1025, duration: 12717557
2021-10-30 13:39:27,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:27,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741850_1026 src: /172.31.29.187:53372 dest: /172.31.29.187:50010
2021-10-30 13:39:27,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53372, dest: /172.31.29.187:50010, bytes: 992237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741850_1026, duration: 13890858
2021-10-30 13:39:27,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:28,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741851_1027 src: /172.31.29.187:53376 dest: /172.31.29.187:50010
2021-10-30 13:39:28,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53376, dest: /172.31.29.187:50010, bytes: 10910814, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741851_1027, duration: 95203154
2021-10-30 13:39:28,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:28,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741852_1028 src: /172.31.29.187:53380 dest: /172.31.29.187:50010
2021-10-30 13:39:29,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53380, dest: /172.31.29.187:50010, bytes: 99220506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1507403502_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741852_1028, duration: 888462088
2021-10-30 13:39:29,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:39:30,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2021-10-30 13:39:30,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2021-10-30 13:39:30,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2021-10-30 13:39:30,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2021-10-30 13:39:30,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2021-10-30 13:39:30,967 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741825_1001 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741825
2021-10-30 13:39:30,973 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741826_1002 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741826
2021-10-30 13:39:30,982 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741827_1003 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741827
2021-10-30 13:39:30,990 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741828_1004 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741828
2021-10-30 13:39:30,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741829_1005 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741829
2021-10-30 13:41:39,301 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741843_1019
2021-10-30 13:41:39,302 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741838_1014
2021-10-30 13:41:39,501 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741840_1016
2021-10-30 13:43:48,701 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741845_1021
2021-10-30 13:44:03,906 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741851_1027
2021-10-30 13:44:25,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741853_1029 src: /172.31.29.187:53416 dest: /172.31.29.187:50010
2021-10-30 13:44:25,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53416, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-468128082_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741853_1029, duration: 31426797
2021-10-30 13:44:25,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:44:25,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741854_1030 src: /172.31.29.187:53420 dest: /172.31.29.187:50010
2021-10-30 13:44:25,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53420, dest: /172.31.29.187:50010, bytes: 962, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-468128082_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741854_1030, duration: 11728203
2021-10-30 13:44:25,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:44:25,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741855_1031 src: /172.31.29.187:53424 dest: /172.31.29.187:50010
2021-10-30 13:44:25,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53424, dest: /172.31.29.187:50010, bytes: 321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-468128082_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741855_1031, duration: 5433218
2021-10-30 13:44:25,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:44:25,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741856_1032 src: /172.31.29.187:53428 dest: /172.31.29.187:50010
2021-10-30 13:44:25,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53428, dest: /172.31.29.187:50010, bytes: 88367, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-468128082_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741856_1032, duration: 5494506
2021-10-30 13:44:25,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:44:27,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=ac93b48f-430d-4f92-b2f5-2fa5a6376df1, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-e06bff12-4e43-4d93-b92e-7459e74d1c6a;nsid=1733090601;c=0) Starting thread to transfer BP-6275426-172.31.29.187-1635600829192:blk_1073741853_1029 to 172.31.18.188:50010 
2021-10-30 13:44:27,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-6275426-172.31.29.187-1635600829192:blk_1073741853_1029 (numBytes=270356) to /172.31.18.188:50010
2021-10-30 13:44:33,912 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741856_1032
2021-10-30 13:49:14,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741859_1035 src: /172.31.29.187:53546 dest: /172.31.29.187:50010
2021-10-30 13:49:24,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53546, dest: /172.31.29.187:50010, bytes: 58452180, op: HDFS_WRITE, cliID: DFSClient_attempt_1635600864222_0003_r_000000_0_-1020725642_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741859_1035, duration: 9183893839
2021-10-30 13:49:24,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:49:24,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741860_1036 src: /172.31.18.188:59870 dest: /172.31.29.187:50010
2021-10-30 13:49:24,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:59870, dest: /172.31.29.187:50010, bytes: 355, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1442163092_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741860_1036, duration: 7719942
2021-10-30 13:49:24,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 13:49:31,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741863_1039 src: /172.31.18.188:59886 dest: /172.31.29.187:50010
2021-10-30 13:49:31,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:59886, dest: /172.31.29.187:50010, bytes: 323025, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1829510864_122, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741863_1039, duration: 12100147
2021-10-30 13:49:31,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 13:49:32,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741865_1041 src: /172.31.29.187:53560 dest: /172.31.29.187:50010
2021-10-30 13:49:32,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53560, dest: /172.31.29.187:50010, bytes: 52457, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_112549185_209, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741865_1041, duration: 6092511
2021-10-30 13:49:32,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:49:33,991 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741856_1032 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2021-10-30 13:49:33,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2021-10-30 13:49:33,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2021-10-30 13:49:33,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2021-10-30 13:49:33,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741846_1022 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2021-10-30 13:49:33,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2021-10-30 13:49:33,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2021-10-30 13:49:33,995 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741856_1032 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741856
2021-10-30 13:49:33,995 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2021-10-30 13:49:33,995 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2021-10-30 13:49:33,995 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2021-10-30 13:49:33,996 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741852_1028 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2021-10-30 13:49:33,996 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741853_1029 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2021-10-30 13:49:33,996 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741854_1030 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2021-10-30 13:49:33,996 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2021-10-30 13:49:34,006 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741843_1019 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741843
2021-10-30 13:49:34,009 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741844_1020 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741844
2021-10-30 13:49:34,020 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741845_1021 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741845
2021-10-30 13:49:34,025 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741846_1022 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741846
2021-10-30 13:49:34,033 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741847_1023 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741847
2021-10-30 13:49:34,033 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741848_1024 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741848
2021-10-30 13:49:34,033 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741849_1025 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741849
2021-10-30 13:49:34,034 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741850_1026 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741850
2021-10-30 13:49:34,034 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741851_1027 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741851
2021-10-30 13:49:34,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741852_1028 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741852
2021-10-30 13:49:34,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741853_1029 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741853
2021-10-30 13:49:34,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741854_1030 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741854
2021-10-30 13:49:34,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741855_1031 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741855
2021-10-30 13:49:48,992 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-30 13:49:48,994 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741860_1036 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-30 13:50:29,931 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741859_1035
2021-10-30 13:50:34,934 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741863_1039
2021-10-30 13:50:34,934 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741865_1041
2021-10-30 13:52:49,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741866_1042 src: /172.31.29.187:53580 dest: /172.31.29.187:50010
2021-10-30 13:52:50,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53580, dest: /172.31.29.187:50010, bytes: 58827252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741866_1042, duration: 569412243
2021-10-30 13:52:50,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:50,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741867_1043 src: /172.31.29.187:53584 dest: /172.31.29.187:50010
2021-10-30 13:52:50,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53584, dest: /172.31.29.187:50010, bytes: 59144921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741867_1043, duration: 524942355
2021-10-30 13:52:50,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:51,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741868_1044 src: /172.31.29.187:53588 dest: /172.31.29.187:50010
2021-10-30 13:52:51,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53588, dest: /172.31.29.187:50010, bytes: 59543202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741868_1044, duration: 516201485
2021-10-30 13:52:51,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:51,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741869_1045 src: /172.31.29.187:53592 dest: /172.31.29.187:50010
2021-10-30 13:52:52,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53592, dest: /172.31.29.187:50010, bytes: 59537384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741869_1045, duration: 509594015
2021-10-30 13:52:52,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:52,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741870_1046 src: /172.31.29.187:53596 dest: /172.31.29.187:50010
2021-10-30 13:52:52,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53596, dest: /172.31.29.187:50010, bytes: 59542451, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741870_1046, duration: 562721550
2021-10-30 13:52:52,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:52,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741871_1047 src: /172.31.29.187:53600 dest: /172.31.29.187:50010
2021-10-30 13:52:53,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53600, dest: /172.31.29.187:50010, bytes: 59547448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741871_1047, duration: 529909035
2021-10-30 13:52:53,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:53,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741872_1048 src: /172.31.29.187:53604 dest: /172.31.29.187:50010
2021-10-30 13:52:53,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53604, dest: /172.31.29.187:50010, bytes: 59542886, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741872_1048, duration: 516414839
2021-10-30 13:52:53,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:54,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741873_1049 src: /172.31.29.187:53608 dest: /172.31.29.187:50010
2021-10-30 13:52:54,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53608, dest: /172.31.29.187:50010, bytes: 59542505, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741873_1049, duration: 522264091
2021-10-30 13:52:54,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:54,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741874_1050 src: /172.31.29.187:53612 dest: /172.31.29.187:50010
2021-10-30 13:52:55,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53612, dest: /172.31.29.187:50010, bytes: 59539797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741874_1050, duration: 498916043
2021-10-30 13:52:55,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:55,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741875_1051 src: /172.31.29.187:53616 dest: /172.31.29.187:50010
2021-10-30 13:52:56,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53616, dest: /172.31.29.187:50010, bytes: 59543659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741875_1051, duration: 508312866
2021-10-30 13:52:56,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:52:56,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741876_1052 src: /172.31.29.187:53620 dest: /172.31.29.187:50010
2021-10-30 13:52:56,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53620, dest: /172.31.29.187:50010, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1549050269_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741876_1052, duration: 4416862
2021-10-30 13:52:56,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:53:46,005 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-30 13:53:46,009 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741859_1035 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-30 13:53:47,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741877_1053 src: /172.31.29.187:53638 dest: /172.31.29.187:50010
2021-10-30 13:53:47,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53638, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-645218232_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741877_1053, duration: 28530778
2021-10-30 13:53:47,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:53:47,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741878_1054 src: /172.31.29.187:53642 dest: /172.31.29.187:50010
2021-10-30 13:53:47,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53642, dest: /172.31.29.187:50010, bytes: 1030, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-645218232_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741878_1054, duration: 15050454
2021-10-30 13:53:47,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:53:47,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741879_1055 src: /172.31.29.187:53646 dest: /172.31.29.187:50010
2021-10-30 13:53:47,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53646, dest: /172.31.29.187:50010, bytes: 355, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-645218232_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741879_1055, duration: 6061466
2021-10-30 13:53:47,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:53:47,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741880_1056 src: /172.31.29.187:53650 dest: /172.31.29.187:50010
2021-10-30 13:53:47,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53650, dest: /172.31.29.187:50010, bytes: 88368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-645218232_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741880_1056, duration: 6931665
2021-10-30 13:53:47,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:53:56,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741881_1057 src: /172.31.18.188:59912 dest: /172.31.29.187:50010
2021-10-30 13:53:56,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:59912, dest: /172.31.29.187:50010, bytes: 105130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-447553075_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741881_1057, duration: 48594384
2021-10-30 13:53:56,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 13:53:57,144 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741872_1048
2021-10-30 13:54:02,147 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741876_1052
2021-10-30 13:54:19,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741882_1058 src: /172.31.18.188:59982 dest: /172.31.29.187:50010
2021-10-30 13:56:10,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741883_1059 src: /172.31.29.187:53768 dest: /172.31.29.187:50010
2021-10-30 13:56:19,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53768, dest: /172.31.29.187:50010, bytes: 58095353, op: HDFS_WRITE, cliID: DFSClient_attempt_1635600864222_0004_r_000000_0_-803200867_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741883_1059, duration: 8757968693
2021-10-30 13:56:19,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:56:19,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:59982, dest: /172.31.29.187:50010, bytes: 128931, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-447553075_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741882_1058, duration: 120324999012
2021-10-30 13:56:19,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 13:56:19,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741884_1060 src: /172.31.18.188:60084 dest: /172.31.29.187:50010
2021-10-30 13:56:19,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:60084, dest: /172.31.29.187:50010, bytes: 355, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-447553075_1, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741884_1060, duration: 8843064
2021-10-30 13:56:19,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 13:56:22,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741877_1053 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741877 for deletion
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741878_1054 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741878 for deletion
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741879_1055 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741879 for deletion
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741880_1056 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741880 for deletion
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741881_1057 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741881 for deletion
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741882_1058 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741882 for deletion
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741877_1053 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741877
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741878_1054 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741878
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741879_1055 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741879
2021-10-30 13:56:22,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741880_1056 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741880
2021-10-30 13:56:22,019 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741881_1057 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741881
2021-10-30 13:56:22,019 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741882_1058 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741882
2021-10-30 13:56:26,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741888_1064 src: /172.31.29.187:53780 dest: /172.31.29.187:50010
2021-10-30 13:56:26,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53780, dest: /172.31.29.187:50010, bytes: 60537, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1608339186_309, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741888_1064, duration: 4943381
2021-10-30 13:56:26,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741888_1064, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-10-30 13:56:26,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-6275426-172.31.29.187-1635600829192:blk_1073741889_1065 src: /172.31.16.191:53846 dest: /172.31.29.187:50010
2021-10-30 13:56:26,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:53846, dest: /172.31.29.187:50010, bytes: 23028, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_547190432_164, offset: 0, srvID: ac93b48f-430d-4f92-b2f5-2fa5a6376df1, blockid: BP-6275426-172.31.29.187-1635600829192:blk_1073741889_1065, duration: 6653268
2021-10-30 13:56:26,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-6275426-172.31.29.187-1635600829192:blk_1073741889_1065, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 13:57:22,757 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741883_1059
2021-10-30 13:57:27,759 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-6275426-172.31.29.187-1635600829192:blk_1073741889_1065
2021-10-30 13:58:49,025 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741884_1060 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741884 for deletion
2021-10-30 13:58:49,026 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-6275426-172.31.29.187-1635600829192 blk_1073741884_1060 file /tmp/hadoop-ubuntu/dfs/data/current/BP-6275426-172.31.29.187-1635600829192/current/finalized/subdir0/subdir0/blk_1073741884
2021-10-30 14:03:55,046 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "hadoopmaster/172.31.29.187"; destination host is: "hadoopmaster":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	at org.apache.hadoop.ipc.Client.call(Client.java:1400)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:617)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:715)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:889)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)
2021-10-30 14:03:58,169 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-30 14:03:58,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 14:04:52,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 14:04:52,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 14:04:53,275 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 14:04:53,364 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 14:04:53,364 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 14:04:53,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 14:04:53,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 14:04:53,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 14:04:53,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 14:04:53,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 14:04:53,454 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 14:04:53,457 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 14:04:53,466 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 14:04:53,467 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 14:04:53,467 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 14:04:53,467 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 14:04:53,478 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 14:04:53,480 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 14:04:53,480 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 14:04:53,636 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 14:04:53,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 14:04:53,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 14:04:53,697 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 14:04:53,713 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 14:04:53,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 14:04:53,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 14:04:53,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 14:04:53,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 14:04:53,778 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 14:04:53,780 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 14:04:54,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 6115@hadoopmaster
2021-10-30 14:04:54,057 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-ubuntu/dfs/data: namenode clusterID = CID-c806406d-2463-4366-bc38-85dbf36f9d89; datanode clusterID = CID-e06bff12-4e43-4d93-b92e-7459e74d1c6a
2021-10-30 14:04:54,057 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1338)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1304)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:04:54,059 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020
2021-10-30 14:04:54,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-10-30 14:04:56,160 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-10-30 14:04:56,162 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-10-30 14:04:56,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 14:05:44,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 14:05:44,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 14:05:45,256 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 14:05:45,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 14:05:45,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 14:05:45,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 14:05:45,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 14:05:45,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 14:05:45,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 14:05:45,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 14:05:45,435 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 14:05:45,438 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 14:05:45,446 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 14:05:45,448 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 14:05:45,448 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 14:05:45,448 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 14:05:45,459 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 14:05:45,461 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 14:05:45,461 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 14:05:45,613 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 14:05:45,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 14:05:45,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 14:05:45,672 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 14:05:45,685 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 14:05:45,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 14:05:45,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 14:05:45,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 14:05:45,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 14:05:45,762 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 14:05:45,764 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 14:05:45,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 7204@hadoopmaster
2021-10-30 14:05:45,907 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-ubuntu/dfs/data: namenode clusterID = CID-c806406d-2463-4366-bc38-85dbf36f9d89; datanode clusterID = CID-e06bff12-4e43-4d93-b92e-7459e74d1c6a
2021-10-30 14:05:45,907 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1338)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1304)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:314)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:226)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:867)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:05:45,909 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020
2021-10-30 14:05:45,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-10-30 14:05:47,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-10-30 14:05:47,912 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-10-30 14:05:47,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 14:07:50,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 14:07:50,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 14:07:51,054 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 14:07:51,137 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 14:07:51,137 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 14:07:51,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 14:07:51,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 14:07:51,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 14:07:51,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 14:07:51,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 14:07:51,221 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 14:07:51,224 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 14:07:51,232 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 14:07:51,234 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 14:07:51,234 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 14:07:51,234 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 14:07:51,246 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 14:07:51,248 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 14:07:51,248 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 14:07:51,405 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 14:07:51,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 14:07:51,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 14:07:51,472 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 14:07:51,485 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 14:07:51,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 14:07:51,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 14:07:51,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 14:07:51,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 14:07:51,555 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 14:07:51,562 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 14:07:51,871 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 1639@hadoopmaster
2021-10-30 14:07:51,872 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:51,872 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 14:07:51,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:51,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:51,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768 is not formatted for BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:51,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 14:07:51,930 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1170698605-172.31.29.187-1635602859768 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current
2021-10-30 14:07:51,935 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-30 14:07:51,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=921491116;bpid=BP-1170698605-172.31.29.187-1635602859768;lv=-56;nsInfo=lv=-60;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0;bpid=BP-1170698605-172.31.29.187-1635602859768;dnuuid=null
2021-10-30 14:07:51,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 8a299b51-632b-414b-a7a5-0495cbfb79ad
2021-10-30 14:07:51,970 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-30 14:07:51,970 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-30 14:07:51,974 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-30 14:07:51,975 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:51,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1170698605-172.31.29.187-1635602859768 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 14:07:51,988 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1170698605-172.31.29.187-1635602859768 on /tmp/hadoop-ubuntu/dfs/data/current: 12ms
2021-10-30 14:07:51,988 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1170698605-172.31.29.187-1635602859768: 13ms
2021-10-30 14:07:51,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1170698605-172.31.29.187-1635602859768 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 14:07:51,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1170698605-172.31.29.187-1635602859768 on volume /tmp/hadoop-ubuntu/dfs/data/current: 0ms
2021-10-30 14:07:51,989 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-10-30 14:07:51,991 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635619733991 with interval 21600000
2021-10-30 14:07:51,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1170698605-172.31.29.187-1635602859768 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-30 14:07:52,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1170698605-172.31.29.187-1635602859768 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-30 14:07:52,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-30 14:07:52,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1170698605-172.31.29.187-1635602859768 (Datanode Uuid 8a299b51-632b-414b-a7a5-0495cbfb79ad) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-30 14:07:52,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1170698605-172.31.29.187-1635602859768 (Datanode Uuid 8a299b51-632b-414b-a7a5-0495cbfb79ad) service to hadoopmaster/172.31.29.187:8020
2021-10-30 14:07:52,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x95c820977,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-30 14:07:52,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:52,221 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-30 14:07:52,221 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-30 14:07:52,222 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-30 14:07:52,222 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-30 14:07:52,223 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-1170698605-172.31.29.187-1635602859768
2021-10-30 14:07:52,226 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-1170698605-172.31.29.187-1635602859768 to blockPoolScannerMap, new size=1
2021-10-30 14:08:32,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741825_1001 src: /172.31.29.187:51148 dest: /172.31.29.187:50010
2021-10-30 14:08:32,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51148, dest: /172.31.29.187:50010, bytes: 58827252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741825_1001, duration: 506694535
2021-10-30 14:08:32,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:33,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741826_1002 src: /172.31.29.187:51150 dest: /172.31.29.187:50010
2021-10-30 14:08:33,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51150, dest: /172.31.29.187:50010, bytes: 59144921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741826_1002, duration: 341387969
2021-10-30 14:08:33,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:33,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741827_1003 src: /172.31.29.187:51152 dest: /172.31.29.187:50010
2021-10-30 14:08:34,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51152, dest: /172.31.29.187:50010, bytes: 59543202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741827_1003, duration: 475315644
2021-10-30 14:08:34,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:34,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741828_1004 src: /172.31.29.187:51154 dest: /172.31.29.187:50010
2021-10-30 14:08:35,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51154, dest: /172.31.29.187:50010, bytes: 59537384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741828_1004, duration: 895661408
2021-10-30 14:08:35,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:35,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005 src: /172.31.29.187:51156 dest: /172.31.29.187:50010
2021-10-30 14:08:35,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51156, dest: /172.31.29.187:50010, bytes: 59542451, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005, duration: 898586960
2021-10-30 14:08:35,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:35,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741830_1006 src: /172.31.29.187:51158 dest: /172.31.29.187:50010
2021-10-30 14:08:36,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51158, dest: /172.31.29.187:50010, bytes: 59547448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741830_1006, duration: 898454660
2021-10-30 14:08:36,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:36,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741831_1007 src: /172.31.29.187:51160 dest: /172.31.29.187:50010
2021-10-30 14:08:37,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51160, dest: /172.31.29.187:50010, bytes: 59542886, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741831_1007, duration: 883508511
2021-10-30 14:08:37,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:37,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741832_1008 src: /172.31.29.187:51162 dest: /172.31.29.187:50010
2021-10-30 14:08:38,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51162, dest: /172.31.29.187:50010, bytes: 59542505, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741832_1008, duration: 879537022
2021-10-30 14:08:38,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:38,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009 src: /172.31.29.187:51164 dest: /172.31.29.187:50010
2021-10-30 14:08:39,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51164, dest: /172.31.29.187:50010, bytes: 59539797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009, duration: 889837933
2021-10-30 14:08:39,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:39,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741834_1010 src: /172.31.29.187:51166 dest: /172.31.29.187:50010
2021-10-30 14:08:40,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51166, dest: /172.31.29.187:50010, bytes: 59543659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741834_1010, duration: 903231936
2021-10-30 14:08:40,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:08:40,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741835_1011 src: /172.31.29.187:51168 dest: /172.31.29.187:50010
2021-10-30 14:08:40,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51168, dest: /172.31.29.187:50010, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_714475498_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741835_1011, duration: 1313091
2021-10-30 14:08:40,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:09:38,082 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
2021-10-30 14:09:53,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741836_1012 src: /172.31.29.187:51180 dest: /172.31.29.187:50010
2021-10-30 14:09:53,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51180, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2104742330_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741836_1012, duration: 29683216
2021-10-30 14:09:53,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:09:53,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741837_1013 src: /172.31.29.187:51182 dest: /172.31.29.187:50010
2021-10-30 14:09:53,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51182, dest: /172.31.29.187:50010, bytes: 1030, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2104742330_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741837_1013, duration: 914412
2021-10-30 14:09:53,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:09:53,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741838_1014 src: /172.31.29.187:51184 dest: /172.31.29.187:50010
2021-10-30 14:09:53,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51184, dest: /172.31.29.187:50010, bytes: 245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2104742330_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741838_1014, duration: 972749
2021-10-30 14:09:53,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:09:53,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741839_1015 src: /172.31.29.187:51186 dest: /172.31.29.187:50010
2021-10-30 14:09:53,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51186, dest: /172.31.29.187:50010, bytes: 88368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2104742330_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741839_1015, duration: 3059137
2021-10-30 14:09:53,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:09:59,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741840_1016 src: /172.31.29.187:51208 dest: /172.31.29.187:50010
2021-10-30 14:09:59,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51208, dest: /172.31.29.187:50010, bytes: 105130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_49509098_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741840_1016, duration: 17360723
2021-10-30 14:09:59,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:11:24,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741841_1017 src: /172.31.29.187:51294 dest: /172.31.29.187:50010
2021-10-30 14:12:42,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 src: /172.31.29.187:51412 dest: /172.31.29.187:50010
2021-10-30 14:12:51,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51412, dest: /172.31.29.187:50010, bytes: 58095353, op: HDFS_WRITE, cliID: DFSClient_attempt_1635602883236_0001_r_000000_0_-1004813564_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018, duration: 8829987088
2021-10-30 14:12:51,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:12:51,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51294, dest: /172.31.29.187:50010, bytes: 106794, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_49509098_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741841_1017, duration: 87365464478
2021-10-30 14:12:51,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:12:51,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 src: /172.31.29.187:51418 dest: /172.31.29.187:50010
2021-10-30 14:12:51,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51418, dest: /172.31.29.187:50010, bytes: 353, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_49509098_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019, duration: 1567732
2021-10-30 14:12:51,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:12:51,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 src: /172.31.29.187:51422 dest: /172.31.29.187:50010
2021-10-30 14:12:51,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51422, dest: /172.31.29.187:50010, bytes: 106794, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_49509098_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020, duration: 2358575
2021-10-30 14:12:51,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:12:51,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741845_1021 src: /172.31.29.187:51424 dest: /172.31.29.187:50010
2021-10-30 14:12:51,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51424, dest: /172.31.29.187:50010, bytes: 105130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_49509098_1, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741845_1021, duration: 2674512
2021-10-30 14:12:51,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:12:55,563 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2021-10-30 14:12:55,564 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1170698605-172.31.29.187-1635602859768 blk_1073741840_1016 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741840
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1170698605-172.31.29.187-1635602859768 blk_1073741841_1017 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741841
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1170698605-172.31.29.187-1635602859768 blk_1073741836_1012 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741836
2021-10-30 14:12:55,565 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1170698605-172.31.29.187-1635602859768 blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741837
2021-10-30 14:12:55,566 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1170698605-172.31.29.187-1635602859768 blk_1073741838_1014 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741838
2021-10-30 14:12:55,566 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1170698605-172.31.29.187-1635602859768 blk_1073741839_1015 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/current/finalized/subdir0/subdir0/blk_1073741839
2021-10-30 14:12:58,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1170698605-172.31.29.187-1635602859768:blk_1073741846_1022 src: /172.31.29.187:51438 dest: /172.31.29.187:50010
2021-10-30 14:12:58,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:51438, dest: /172.31.29.187:50010, bytes: 278326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_781842324_79, offset: 0, srvID: 8a299b51-632b-414b-a7a5-0495cbfb79ad, blockid: BP-1170698605-172.31.29.187-1635602859768:blk_1073741846_1022, duration: 10860038
2021-10-30 14:12:58,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1170698605-172.31.29.187-1635602859768:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:13:03,108 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Failed to read previous verification times.
java.io.FileNotFoundException: /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/dncp_block_verification.log.curr (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.openFile(RollingLogsImpl.java:179)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.readNext(RollingLogsImpl.java:192)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.<init>(RollingLogsImpl.java:146)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl$Reader.<init>(RollingLogsImpl.java:136)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl.iterator(RollingLogsImpl.java:97)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl.iterator(RollingLogsImpl.java:36)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.assignInitialVerificationTimes(BlockPoolSliceScanner.java:546)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:645)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting CheckDiskError Thread
2021-10-30 14:13:03,110 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
java.io.IOException: BlockId 1073741829 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,111 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
java.io.IOException: BlockId 1073741829 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,111 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
2021-10-30 14:13:03,142 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009
java.io.IOException: BlockId 1073741833 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,143 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009
java.io.IOException: BlockId 1073741833 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,143 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009
2021-10-30 14:13:03,145 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,145 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:03,146 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018
2021-10-30 14:13:03,147 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Received exception: 
java.io.IOException: Failed to rename /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/dncp_block_verification.log.curr to /tmp/hadoop-ubuntu/dfs/data/current/BP-1170698605-172.31.29.187-1635602859768/dncp_block_verification.log.prev
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RollingLogsImpl.roll(RollingLogsImpl.java:120)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.rollVerificationLogs(BlockPoolSliceScanner.java:716)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:697)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,148 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
java.io.IOException: BlockId 1073741829 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,149 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
java.io.IOException: BlockId 1073741829 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,149 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741829_1005
2021-10-30 14:13:08,150 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009
java.io.IOException: BlockId 1073741833 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,151 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009
java.io.IOException: BlockId 1073741833 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,151 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741833_1009
2021-10-30 14:13:08,152 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,152 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,152 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018
2021-10-30 14:13:08,159 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: First Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741846_1022
java.io.IOException: BlockId 1073741846 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,159 WARN org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Second Verification failed for BP-1170698605-172.31.29.187-1635602859768:blk_1073741846_1022
java.io.IOException: BlockId 1073741846 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(BlockPoolSliceScanner.java:436)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyFirstBlock(BlockPoolSliceScanner.java:523)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan(BlockPoolSliceScanner.java:684)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scanBlockPoolSlice(BlockPoolSliceScanner.java:650)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:101)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:13:08,159 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Reporting bad BP-1170698605-172.31.29.187-1635602859768:blk_1073741846_1022
2021-10-30 14:14:22,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 received exception java.io.IOException: BlockId 1073741843 is not valid.
2021-10-30 14:14:22,156 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 to /172.31.29.187:51448
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:22,156 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51448 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:24,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 received exception java.io.IOException: BlockId 1073741843 is not valid.
2021-10-30 14:14:24,630 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 to /172.31.29.187:51450
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:24,630 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51450 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:27,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 received exception java.io.IOException: BlockId 1073741843 is not valid.
2021-10-30 14:14:27,669 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 to /172.31.29.187:51452
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:27,669 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51452 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:37,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 received exception java.io.IOException: BlockId 1073741843 is not valid.
2021-10-30 14:14:37,404 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741843_1019 to /172.31.29.187:51454
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:14:37,404 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51454 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741843 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:35:09,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 received exception java.io.IOException: BlockId 1073741842 is not valid.
2021-10-30 14:35:09,680 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 to /172.31.29.187:51560
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:35:09,681 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51560 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:35:10,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 received exception java.io.IOException: BlockId 1073741842 is not valid.
2021-10-30 14:35:10,567 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 to /172.31.29.187:51562
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:35:10,568 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51562 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:21,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:21,685 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51572
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:21,686 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51572 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:24,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:24,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51574
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:24,402 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51574 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:28,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 received exception java.io.IOException: BlockId 1073741842 is not valid.
2021-10-30 14:36:28,687 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 to /172.31.29.187:51578
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:28,687 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51578 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:29,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 received exception java.io.IOException: BlockId 1073741842 is not valid.
2021-10-30 14:36:29,013 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741842_1018 to /172.31.29.187:51580
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:29,013 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51580 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741842 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:31,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:31,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51582
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:31,866 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51582 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:39,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:39,100 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51584
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:39,102 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51584 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:50,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:50,716 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51588
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:50,716 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51588 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:53,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:53,408 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51590
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:53,408 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51590 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:58,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:36:58,007 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51594
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:36:58,007 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51594 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:37:05,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 received exception java.io.IOException: BlockId 1073741844 is not valid.
2021-10-30 14:37:05,982 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=8a299b51-632b-414b-a7a5-0495cbfb79ad, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-3f58110d-d83a-4e54-b0aa-2063a764fb7d;nsid=921491116;c=0):Got exception while serving BP-1170698605-172.31.29.187-1635602859768:blk_1073741844_1020 to /172.31.29.187:51596
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:37:05,983 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:51596 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741844 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-10-30 14:37:13,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 14:37:13,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 14:37:13,869 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 14:37:13,950 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 14:37:13,950 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 14:37:13,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 14:37:13,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 14:37:13,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-10-30 14:37:13,980 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:720)
	at org.apache.hadoop.ipc.Server.bind(Server.java:424)
	at org.apache.hadoop.ipc.Server.bind(Server.java:396)
	at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:111)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:871)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1084)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2328)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2215)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2262)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2438)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2462)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:461)
	at sun.nio.ch.Net.bind(Net.java:453)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:222)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:85)
	at org.apache.hadoop.ipc.Server.bind(Server.java:407)
	... 10 more
2021-10-30 14:37:13,985 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-10-30 14:37:13,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 14:37:33,269 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-30 14:37:33,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-10-30 14:39:25,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-30 14:39:25,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-30 14:39:26,335 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-10-30 14:39:26,420 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-10-30 14:39:26,420 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-30 14:39:26,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-10-30 14:39:26,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-30 14:39:26,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-10-30 14:39:26,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-10-30 14:39:26,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-10-30 14:39:26,503 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-10-30 14:39:26,507 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-30 14:39:26,515 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-30 14:39:26,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-30 14:39:26,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-30 14:39:26,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-30 14:39:26,528 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-10-30 14:39:26,531 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-10-30 14:39:26,531 INFO org.mortbay.log: jetty-6.1.26
2021-10-30 14:39:26,706 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-10-30 14:39:26,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-10-30 14:39:26,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-30 14:39:26,775 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-10-30 14:39:26,790 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-10-30 14:39:26,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-10-30 14:39:26,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-30 14:39:26,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-30 14:39:26,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-10-30 14:39:26,854 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-30 14:39:26,855 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-10-30 14:39:27,173 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 1602@hadoopmaster
2021-10-30 14:39:27,174 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,174 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 14:39:27,235 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,236 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,236 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728 is not formatted for BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,236 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-10-30 14:39:27,236 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-741289314-172.31.29.187-1635604753728 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current
2021-10-30 14:39:27,240 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-10-30 14:39:27,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=636841818;bpid=BP-741289314-172.31.29.187-1635604753728;lv=-56;nsInfo=lv=-60;cid=CID-4f5fcdc1-215b-4ad5-920d-45ffa7082e31;nsid=636841818;c=0;bpid=BP-741289314-172.31.29.187-1635604753728;dnuuid=null
2021-10-30 14:39:27,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709
2021-10-30 14:39:27,275 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-10-30 14:39:27,276 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-10-30 14:39:27,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-30 14:39:27,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-741289314-172.31.29.187-1635604753728 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 14:39:27,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-741289314-172.31.29.187-1635604753728 on /tmp/hadoop-ubuntu/dfs/data/current: 12ms
2021-10-30 14:39:27,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-741289314-172.31.29.187-1635604753728: 13ms
2021-10-30 14:39:27,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-741289314-172.31.29.187-1635604753728 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-10-30 14:39:27,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-741289314-172.31.29.187-1635604753728 on volume /tmp/hadoop-ubuntu/dfs/data/current: 0ms
2021-10-30 14:39:27,295 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-10-30 14:39:27,297 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1635611869297 with interval 21600000
2021-10-30 14:39:27,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-741289314-172.31.29.187-1635604753728 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-10-30 14:39:27,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-741289314-172.31.29.187-1635604753728 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-10-30 14:39:27,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-30 14:39:27,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-741289314-172.31.29.187-1635604753728 (Datanode Uuid 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=1
2021-10-30 14:39:27,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-741289314-172.31.29.187-1635604753728 (Datanode Uuid 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709) service to hadoopmaster/172.31.29.187:8020
2021-10-30 14:39:27,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x84bf01453,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-30 14:39:27,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,516 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-10-30 14:39:27,516 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-10-30 14:39:27,517 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-10-30 14:39:27,517 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-10-30 14:39:27,517 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-741289314-172.31.29.187-1635604753728
2021-10-30 14:39:27,520 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-741289314-172.31.29.187-1635604753728 to blockPoolScannerMap, new size=1
2021-10-30 14:40:12,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741825_1001 src: /172.31.29.187:47588 dest: /172.31.29.187:50010
2021-10-30 14:40:13,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47588, dest: /172.31.29.187:50010, bytes: 58827252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741825_1001, duration: 506074363
2021-10-30 14:40:13,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:13,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741826_1002 src: /172.31.29.187:47590 dest: /172.31.29.187:50010
2021-10-30 14:40:13,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47590, dest: /172.31.29.187:50010, bytes: 59144921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741826_1002, duration: 433477282
2021-10-30 14:40:13,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:13,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741827_1003 src: /172.31.29.187:47592 dest: /172.31.29.187:50010
2021-10-30 14:40:14,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47592, dest: /172.31.29.187:50010, bytes: 59543202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741827_1003, duration: 751176658
2021-10-30 14:40:14,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:14,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741828_1004 src: /172.31.29.187:47594 dest: /172.31.29.187:50010
2021-10-30 14:40:15,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47594, dest: /172.31.29.187:50010, bytes: 59537384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741828_1004, duration: 891369641
2021-10-30 14:40:15,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:16,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741829_1005 src: /172.31.29.187:47596 dest: /172.31.29.187:50010
2021-10-30 14:40:16,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47596, dest: /172.31.29.187:50010, bytes: 59542451, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741829_1005, duration: 499295447
2021-10-30 14:40:16,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:16,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741830_1006 src: /172.31.29.187:47598 dest: /172.31.29.187:50010
2021-10-30 14:40:17,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47598, dest: /172.31.29.187:50010, bytes: 59547448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741830_1006, duration: 807005250
2021-10-30 14:40:17,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:18,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741831_1007 src: /172.31.29.187:47600 dest: /172.31.29.187:50010
2021-10-30 14:40:18,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47600, dest: /172.31.29.187:50010, bytes: 59542886, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741831_1007, duration: 369331465
2021-10-30 14:40:18,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:18,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741832_1008 src: /172.31.29.187:47602 dest: /172.31.29.187:50010
2021-10-30 14:40:19,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47602, dest: /172.31.29.187:50010, bytes: 59542505, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741832_1008, duration: 881869700
2021-10-30 14:40:19,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:19,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741833_1009 src: /172.31.29.187:47604 dest: /172.31.29.187:50010
2021-10-30 14:40:20,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47604, dest: /172.31.29.187:50010, bytes: 59539797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741833_1009, duration: 907831523
2021-10-30 14:40:20,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:20,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741834_1010 src: /172.31.29.187:47606 dest: /172.31.29.187:50010
2021-10-30 14:40:21,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47606, dest: /172.31.29.187:50010, bytes: 59543659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741834_1010, duration: 904069400
2021-10-30 14:40:21,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:21,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741835_1011 src: /172.31.29.187:47608 dest: /172.31.29.187:50010
2021-10-30 14:40:21,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47608, dest: /172.31.29.187:50010, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-975282561_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741835_1011, duration: 1276765
2021-10-30 14:40:21,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:53,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741836_1012 src: /172.31.29.187:47618 dest: /172.31.29.187:50010
2021-10-30 14:40:53,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47618, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1784628598_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741836_1012, duration: 27002618
2021-10-30 14:40:53,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:53,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741837_1013 src: /172.31.29.187:47620 dest: /172.31.29.187:50010
2021-10-30 14:40:53,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47620, dest: /172.31.29.187:50010, bytes: 1030, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1784628598_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741837_1013, duration: 4741226
2021-10-30 14:40:53,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:53,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741838_1014 src: /172.31.29.187:47622 dest: /172.31.29.187:50010
2021-10-30 14:40:53,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47622, dest: /172.31.29.187:50010, bytes: 245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1784628598_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741838_1014, duration: 3695708
2021-10-30 14:40:53,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:40:53,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741839_1015 src: /172.31.29.187:47624 dest: /172.31.29.187:50010
2021-10-30 14:40:53,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47624, dest: /172.31.29.187:50010, bytes: 88368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1784628598_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741839_1015, duration: 5268769
2021-10-30 14:40:53,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:41:18,401 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-741289314-172.31.29.187-1635604753728:blk_1073741829_1005
2021-10-30 14:43:33,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741840_1016 src: /172.31.29.187:47656 dest: /172.31.29.187:50010
2021-10-30 14:43:33,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47656, dest: /172.31.29.187:50010, bytes: 270356, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-495589231_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741840_1016, duration: 30978108
2021-10-30 14:43:33,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:43:33,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741841_1017 src: /172.31.29.187:47658 dest: /172.31.29.187:50010
2021-10-30 14:43:33,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47658, dest: /172.31.29.187:50010, bytes: 1030, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-495589231_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741841_1017, duration: 1236968
2021-10-30 14:43:33,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:43:33,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741842_1018 src: /172.31.29.187:47660 dest: /172.31.29.187:50010
2021-10-30 14:43:33,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47660, dest: /172.31.29.187:50010, bytes: 245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-495589231_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741842_1018, duration: 1644292
2021-10-30 14:43:33,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:43:34,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741843_1019 src: /172.31.29.187:47662 dest: /172.31.29.187:50010
2021-10-30 14:43:34,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47662, dest: /172.31.29.187:50010, bytes: 88368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-495589231_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741843_1019, duration: 1219303
2021-10-30 14:43:34,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:43:39,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741844_1020 src: /172.31.29.187:47682 dest: /172.31.29.187:50010
2021-10-30 14:43:39,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47682, dest: /172.31.29.187:50010, bytes: 105130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1649013878_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741844_1020, duration: 34127959
2021-10-30 14:43:39,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:45:05,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741845_1021 src: /172.31.29.187:47774 dest: /172.31.29.187:50010
2021-10-30 14:46:25,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741846_1022 src: /172.31.29.187:47886 dest: /172.31.29.187:50010
2021-10-30 14:46:34,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47886, dest: /172.31.29.187:50010, bytes: 58095353, op: HDFS_WRITE, cliID: DFSClient_attempt_1635604980059_0001_r_000000_0_568978603_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741846_1022, duration: 8924440660
2021-10-30 14:46:34,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:46:34,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47774, dest: /172.31.29.187:50010, bytes: 106787, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1649013878_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741845_1021, duration: 88571372067
2021-10-30 14:46:34,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:46:34,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741847_1023 src: /172.31.29.187:47894 dest: /172.31.29.187:50010
2021-10-30 14:46:34,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47894, dest: /172.31.29.187:50010, bytes: 353, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1649013878_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741847_1023, duration: 4215182
2021-10-30 14:46:34,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:46:34,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741848_1024 src: /172.31.29.187:47898 dest: /172.31.29.187:50010
2021-10-30 14:46:34,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47898, dest: /172.31.29.187:50010, bytes: 106787, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1649013878_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741848_1024, duration: 2770033
2021-10-30 14:46:34,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:46:34,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741849_1025 src: /172.31.29.187:47900 dest: /172.31.29.187:50010
2021-10-30 14:46:34,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47900, dest: /172.31.29.187:50010, bytes: 105130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1649013878_1, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741849_1025, duration: 1915243
2021-10-30 14:46:34,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:46:39,898 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2021-10-30 14:46:39,900 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741840_1016 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741840
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741841_1017 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741841
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741842_1018 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741842
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741843_1019 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741843
2021-10-30 14:46:39,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741844_1020 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741844
2021-10-30 14:46:39,902 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741845_1021 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741845
2021-10-30 14:46:42,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-741289314-172.31.29.187-1635604753728:blk_1073741850_1026 src: /172.31.29.187:47906 dest: /172.31.29.187:50010
2021-10-30 14:46:42,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:47906, dest: /172.31.29.187:50010, bytes: 283001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-550156968_93, offset: 0, srvID: 9fd7ae4c-0bab-4979-9a36-6cdd27e6c709, blockid: BP-741289314-172.31.29.187-1635604753728:blk_1073741850_1026, duration: 23866892
2021-10-30 14:46:42,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-741289314-172.31.29.187-1635604753728:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-10-30 14:48:15,888 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2021-10-30 14:48:15,889 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-741289314-172.31.29.187-1635604753728 blk_1073741847_1023 file /tmp/hadoop-ubuntu/dfs/data/current/BP-741289314-172.31.29.187-1635604753728/current/finalized/subdir0/subdir0/blk_1073741847
2021-10-30 15:02:05,247 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-30 15:02:05,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-11-04 11:19:09,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-11-04 11:19:09,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-11-04 11:19:10,452 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-11-04 11:19:10,539 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-11-04 11:19:10,539 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-11-04 11:19:10,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-11-04 11:19:10,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-11-04 11:19:10,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-11-04 11:19:10,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-11-04 11:19:10,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-11-04 11:19:10,631 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-11-04 11:19:10,634 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-11-04 11:19:10,642 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-11-04 11:19:10,644 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-11-04 11:19:10,644 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-11-04 11:19:10,644 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-11-04 11:19:10,655 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-11-04 11:19:10,657 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-11-04 11:19:10,657 INFO org.mortbay.log: jetty-6.1.26
2021-11-04 11:19:10,830 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-11-04 11:19:10,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-11-04 11:19:10,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-11-04 11:19:10,921 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-11-04 11:19:10,934 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-11-04 11:19:10,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-11-04 11:19:10,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-11-04 11:19:10,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-11-04 11:19:11,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-11-04 11:19:11,014 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-11-04 11:19:11,022 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-11-04 11:19:12,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:13,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:14,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:15,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:16,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:17,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:18,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:19,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:20,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:21,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:21,149 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:19:27,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:28,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:29,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:30,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:31,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:32,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:33,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:34,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:35,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:36,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:36,158 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:19:42,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:43,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:44,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:45,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:46,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:47,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:48,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:49,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:50,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:51,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:51,166 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:19:57,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:58,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:19:59,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:00,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:01,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:02,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:03,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:04,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:05,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:06,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:06,176 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:20:12,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:13,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:14,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:15,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:16,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:17,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:18,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:19,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:20,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:21,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:21,184 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:20:27,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:28,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:29,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:30,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:31,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:32,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:33,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:34,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:35,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:36,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:36,192 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:20:42,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:43,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:44,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:45,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:46,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:47,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:48,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:49,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:50,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:51,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:51,201 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:20:57,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:58,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:20:59,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:00,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:01,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:02,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:03,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:04,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:05,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:06,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:06,210 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:21:12,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:13,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:14,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:15,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:16,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:17,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:18,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:19,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:20,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:21,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:21,218 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:21:27,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:28,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:29,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:30,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:31,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:32,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:33,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:34,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:35,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:36,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:36,227 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:21:42,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:43,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:44,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:45,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:46,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:47,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:48,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:49,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:50,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:51,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:51,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:21:57,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:58,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:21:59,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:00,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:01,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:02,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:03,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:04,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:05,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:06,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:06,244 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:22:12,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:13,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:14,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:15,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:16,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:17,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:18,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:19,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:20,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:21,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:21,253 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:22:27,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:28,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:29,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:30,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:31,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:32,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:33,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:34,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:35,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:36,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:36,261 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:22:42,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:43,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:44,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:45,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:46,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:47,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:48,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:49,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:50,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:51,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:51,269 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:22:57,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:58,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:22:59,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:00,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:01,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:02,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:03,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:04,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:05,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:06,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:06,278 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:23:12,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:13,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:14,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:15,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:16,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:17,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:18,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:19,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:20,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:21,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:21,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:23:27,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:28,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:29,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:30,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:31,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:32,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:33,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:34,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:35,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:36,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:36,294 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:23:42,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:43,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:44,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:45,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:46,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:47,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:48,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:49,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:50,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:51,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:51,302 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:23:57,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:58,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:23:59,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:00,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:01,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:02,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:03,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:04,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:05,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:06,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:06,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:24:12,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:13,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:14,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:15,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:16,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:17,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:18,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:19,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:20,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:21,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:21,319 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:24:27,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:28,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:29,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:30,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:31,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:32,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:33,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:34,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:35,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:36,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:36,327 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:24:42,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:43,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:44,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:45,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:46,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:47,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:48,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:49,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:50,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:51,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:51,337 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:24:57,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:58,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:24:59,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:00,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:01,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:02,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:03,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:04,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:05,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:06,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:06,346 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:25:12,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:13,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:14,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:15,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:16,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:17,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:18,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:19,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:20,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:21,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:21,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:25:27,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:28,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:29,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:30,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:31,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:32,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:33,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:34,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:35,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:36,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:36,362 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:25:42,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:43,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:44,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:45,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:46,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:47,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:48,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:49,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:50,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:51,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:51,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:25:57,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:58,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:25:59,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:00,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:01,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:02,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:03,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:04,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:05,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:06,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:06,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:26:12,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:13,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:14,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:15,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:16,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:17,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:18,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:19,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:20,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:21,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:21,386 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:26:27,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:28,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:29,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:30,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:31,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:32,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:33,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:34,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:35,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:36,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:36,394 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:26:42,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:43,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:44,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:45,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:46,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:47,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:48,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:49,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:50,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:51,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:51,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:26:57,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:58,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:26:59,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:00,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:01,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:02,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:03,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:04,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:05,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:06,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:06,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:27:12,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:13,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:14,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:15,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:16,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:17,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:18,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:19,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:20,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:21,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:21,417 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:27:27,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:28,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:29,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:30,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:31,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:32,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:33,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:34,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:35,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:36,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:36,425 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:27:42,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:43,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:44,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:45,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:46,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:47,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:48,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:49,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:50,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:51,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:51,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:27:57,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:58,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:27:59,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:00,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:01,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:02,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:03,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:04,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:05,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:06,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:06,441 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:28:12,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:13,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:14,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:15,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:16,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:17,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:18,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:19,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:20,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:21,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:21,449 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:28:27,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:28,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:29,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:30,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:31,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:32,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:33,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:34,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:35,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:36,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:36,457 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:28:42,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:43,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:44,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:45,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:46,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:47,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:48,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:49,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:50,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:51,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:51,464 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:28:57,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:58,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:28:59,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:00,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:01,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:02,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:03,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:04,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:05,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:06,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:06,471 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:29:12,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:13,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:14,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:15,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:16,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:17,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:18,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:19,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:20,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:21,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:21,478 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:29:27,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:28,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:29,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:30,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:31,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:32,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:33,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:34,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:35,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:36,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:36,486 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:29:42,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:43,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:44,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:45,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:46,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:47,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:48,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:49,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:50,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:51,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:51,494 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:29:57,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:58,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:29:59,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:00,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:01,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:02,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:03,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:04,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:05,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:06,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:06,501 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:30:12,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:13,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:14,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:15,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:16,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:17,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:18,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:19,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:20,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:21,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoopmaster/172.31.29.187:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-11-04 11:30:21,509 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: hadoopmaster/172.31.29.187:8020
2021-11-04 11:30:25,545 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-11-04 11:30:25,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-11-04 11:31:06,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-11-04 11:31:06,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-11-04 11:31:06,923 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-11-04 11:31:07,068 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-11-04 11:31:07,068 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-11-04 11:31:07,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-11-04 11:31:07,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-11-04 11:31:07,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-11-04 11:31:07,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-11-04 11:31:07,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-11-04 11:31:07,208 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-11-04 11:31:07,211 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-11-04 11:31:07,220 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-11-04 11:31:07,221 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-11-04 11:31:07,222 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-11-04 11:31:07,222 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-11-04 11:31:07,236 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-11-04 11:31:07,241 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2021-11-04 11:31:07,241 INFO org.mortbay.log: jetty-6.1.26
2021-11-04 11:31:07,472 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2021-11-04 11:31:07,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = ubuntu
2021-11-04 11:31:07,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-11-04 11:31:07,532 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-11-04 11:31:07,546 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-11-04 11:31:07,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-11-04 11:31:07,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-11-04 11:31:07,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-11-04 11:31:07,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to hadoopmaster/172.31.29.187:8020 starting to offer service
2021-11-04 11:31:07,614 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-11-04 11:31:07,616 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-11-04 11:31:07,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-ubuntu/dfs/data/in_use.lock acquired by nodename 6572@hadoopmaster
2021-11-04 11:31:07,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted for BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:07,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-11-04 11:31:07,891 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:07,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:07,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820 is not formatted for BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:07,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-11-04 11:31:07,892 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1852784058-172.31.29.187-1636025418820 directory /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current
2021-11-04 11:31:07,896 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-11-04 11:31:07,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1798636716;bpid=BP-1852784058-172.31.29.187-1636025418820;lv=-56;nsInfo=lv=-60;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0;bpid=BP-1852784058-172.31.29.187-1636025418820;dnuuid=null
2021-11-04 11:31:07,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 19b9991c-5f77-4ac9-a12c-f97983ab83b8
2021-11-04 11:31:07,932 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /tmp/hadoop-ubuntu/dfs/data/current
2021-11-04 11:31:07,932 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-ubuntu/dfs/data/current, StorageType: DISK
2021-11-04 11:31:07,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-11-04 11:31:07,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:07,938 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1852784058-172.31.29.187-1636025418820 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-11-04 11:31:07,946 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1852784058-172.31.29.187-1636025418820 on /tmp/hadoop-ubuntu/dfs/data/current: 8ms
2021-11-04 11:31:07,946 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1852784058-172.31.29.187-1636025418820: 10ms
2021-11-04 11:31:07,947 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1852784058-172.31.29.187-1636025418820 on volume /tmp/hadoop-ubuntu/dfs/data/current...
2021-11-04 11:31:07,947 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1852784058-172.31.29.187-1636025418820 on volume /tmp/hadoop-ubuntu/dfs/data/current: 0ms
2021-11-04 11:31:07,947 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-11-04 11:31:07,949 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1636027104949 with interval 21600000
2021-11-04 11:31:07,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1852784058-172.31.29.187-1636025418820 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 beginning handshake with NN
2021-11-04 11:31:08,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1852784058-172.31.29.187-1636025418820 (Datanode Uuid null) service to hadoopmaster/172.31.29.187:8020 successfully registered with NN
2021-11-04 11:31:08,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode hadoopmaster/172.31.29.187:8020 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-11-04 11:31:08,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1852784058-172.31.29.187-1636025418820 (Datanode Uuid 19b9991c-5f77-4ac9-a12c-f97983ab83b8) service to hadoopmaster/172.31.29.187:8020 trying to claim ACTIVE state with txid=8
2021-11-04 11:31:08,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1852784058-172.31.29.187-1636025418820 (Datanode Uuid 19b9991c-5f77-4ac9-a12c-f97983ab83b8) service to hadoopmaster/172.31.29.187:8020
2021-11-04 11:31:08,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xb1a4044492,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-11-04 11:31:08,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:08,156 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2021-11-04 11:31:08,156 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-11-04 11:31:08,157 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2021-11-04 11:31:08,157 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2021-11-04 11:31:08,157 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-1852784058-172.31.29.187-1636025418820
2021-11-04 11:31:08,161 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-1852784058-172.31.29.187-1636025418820 to blockPoolScannerMap, new size=1
2021-11-04 11:32:56,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741825_1001 src: /172.31.29.187:52730 dest: /172.31.29.187:50010
2021-11-04 11:32:57,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52730, dest: /172.31.29.187:50010, bytes: 32888333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1571155588_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741825_1001, duration: 532099949
2021-11-04 11:32:57,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:33:32,988 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741825_1001
2021-11-04 11:36:33,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741826_1002 src: /172.31.29.187:52758 dest: /172.31.29.187:50010
2021-11-04 11:36:33,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52758, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741826_1002, duration: 24279753
2021-11-04 11:36:33,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:36:33,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741827_1003 src: /172.31.29.187:52762 dest: /172.31.29.187:50010
2021-11-04 11:36:33,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52762, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741827_1003, duration: 74597333
2021-11-04 11:36:33,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:36:33,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741828_1004 src: /172.31.29.187:52766 dest: /172.31.29.187:50010
2021-11-04 11:36:33,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52766, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741828_1004, duration: 11113401
2021-11-04 11:36:33,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:36:33,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741829_1005 src: /172.31.29.187:52770 dest: /172.31.29.187:50010
2021-11-04 11:36:33,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52770, dest: /172.31.29.187:50010, bytes: 88704, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741829_1005, duration: 13177875
2021-11-04 11:36:33,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:36:35,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0) Starting thread to transfer BP-1852784058-172.31.29.187-1636025418820:blk_1073741826_1002 to 172.31.18.188:50010 
2021-11-04 11:36:35,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-1852784058-172.31.29.187-1636025418820:blk_1073741826_1002 (numBytes=21988) to /172.31.18.188:50010
2021-11-04 11:36:42,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741830_1006 src: /172.31.18.188:44112 dest: /172.31.29.187:50010
2021-11-04 11:36:42,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44112, dest: /172.31.29.187:50010, bytes: 105514, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_45119427_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741830_1006, duration: 81489071
2021-11-04 11:36:42,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:36:43,006 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741829_1005
2021-11-04 11:36:48,014 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741830_1006
2021-11-04 11:37:01,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741832_1008 src: /172.31.29.187:52802 dest: /172.31.29.187:50010
2021-11-04 11:37:04,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52802, dest: /172.31.29.187:50010, bytes: 23358518, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0001_r_000000_0_1732833534_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741832_1008, duration: 2978230099
2021-11-04 11:37:04,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:04,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741833_1009 src: /172.31.18.188:44130 dest: /172.31.29.187:50010
2021-11-04 11:37:04,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44130, dest: /172.31.29.187:50010, bytes: 346, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_45119427_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741833_1009, duration: 3531229
2021-11-04 11:37:04,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:37:04,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741835_1011 src: /172.31.18.188:44140 dest: /172.31.29.187:50010
2021-11-04 11:37:04,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44140, dest: /172.31.29.187:50010, bytes: 105514, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_45119427_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741835_1011, duration: 5701486
2021-11-04 11:37:04,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:37:06,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741836_1012 src: /172.31.29.187:52810 dest: /172.31.29.187:50010
2021-11-04 11:37:06,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52810, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741836_1012, duration: 10405323
2021-11-04 11:37:06,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:06,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741837_1013 src: /172.31.29.187:52814 dest: /172.31.29.187:50010
2021-11-04 11:37:06,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52814, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741837_1013, duration: 18184152
2021-11-04 11:37:06,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:06,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741838_1014 src: /172.31.29.187:52818 dest: /172.31.29.187:50010
2021-11-04 11:37:06,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52818, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741838_1014, duration: 5581588
2021-11-04 11:37:06,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:06,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741839_1015 src: /172.31.29.187:52822 dest: /172.31.29.187:50010
2021-11-04 11:37:06,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52822, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741839_1015, duration: 9575070
2021-11-04 11:37:06,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:08,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741826_1002 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741826
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741827_1003 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741827
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741828_1004 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741828
2021-11-04 11:37:08,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741829_1005 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741829
2021-11-04 11:37:08,070 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741830_1006 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741830
2021-11-04 11:37:11,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-11-04 11:37:11,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741833_1009 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741833
2021-11-04 11:37:11,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741840_1016 src: /172.31.29.187:52840 dest: /172.31.29.187:50010
2021-11-04 11:37:11,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52840, dest: /172.31.29.187:50010, bytes: 9155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-84623596_91, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741840_1016, duration: 31390845
2021-11-04 11:37:11,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:11,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741841_1017 src: /172.31.18.188:44148 dest: /172.31.29.187:50010
2021-11-04 11:37:11,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44148, dest: /172.31.29.187:50010, bytes: 38147, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1556321612_89, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741841_1017, duration: 40468649
2021-11-04 11:37:11,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:37:13,019 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741839_1015
2021-11-04 11:37:14,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0) Starting thread to transfer BP-1852784058-172.31.29.187-1636025418820:blk_1073741836_1012 to 172.31.16.191:50010 
2021-11-04 11:37:14,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-1852784058-172.31.29.187-1636025418820:blk_1073741836_1012 (numBytes=21988) to /172.31.16.191:50010
2021-11-04 11:37:18,022 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741840_1016
2021-11-04 11:37:29,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741843_1019 src: /172.31.16.191:55486 dest: /172.31.29.187:50010
2021-11-04 11:37:43,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55486, dest: /172.31.29.187:50010, bytes: 33772, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-319237801_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741843_1019, duration: 13410600627
2021-11-04 11:37:43,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:37:43,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741845_1021 src: /172.31.16.191:55496 dest: /172.31.29.187:50010
2021-11-04 11:37:43,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55496, dest: /172.31.29.187:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-319237801_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741845_1021, duration: 10197531
2021-11-04 11:37:43,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:37:43,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741846_1022 src: /172.31.16.191:55502 dest: /172.31.29.187:50010
2021-11-04 11:37:43,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55502, dest: /172.31.29.187:50010, bytes: 33772, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-319237801_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741846_1022, duration: 5688374
2021-11-04 11:37:43,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:37:45,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741848_1024 src: /172.31.29.187:52854 dest: /172.31.29.187:50010
2021-11-04 11:37:45,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52854, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741848_1024, duration: 4859144
2021-11-04 11:37:45,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:45,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741849_1025 src: /172.31.29.187:52858 dest: /172.31.29.187:50010
2021-11-04 11:37:45,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52858, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741849_1025, duration: 14522925
2021-11-04 11:37:45,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:45,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741850_1026 src: /172.31.29.187:52862 dest: /172.31.29.187:50010
2021-11-04 11:37:45,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52862, dest: /172.31.29.187:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741850_1026, duration: 4211697
2021-11-04 11:37:45,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:45,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741851_1027 src: /172.31.29.187:52866 dest: /172.31.29.187:50010
2021-11-04 11:37:45,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52866, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741851_1027, duration: 13705101
2021-11-04 11:37:45,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:48,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741852_1028 src: /172.31.29.187:52892 dest: /172.31.29.187:50010
2021-11-04 11:37:48,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52892, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_577502487_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741852_1028, duration: 16526158
2021-11-04 11:37:48,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:37:50,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2021-11-04 11:37:50,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2021-11-04 11:37:50,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741843_1019 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741843
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741845_1021 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741845
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741836_1012 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741836
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741837_1013 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741837
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741838_1014 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741838
2021-11-04 11:37:50,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741839_1015 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741839
2021-11-04 11:37:53,028 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741848_1024
2021-11-04 11:37:58,032 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741852_1028
2021-11-04 11:38:03,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741855_1031 src: /172.31.29.187:52906 dest: /172.31.29.187:50010
2021-11-04 11:38:17,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52906, dest: /172.31.29.187:50010, bytes: 33758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_577502487_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741855_1031, duration: 14343334593
2021-11-04 11:38:17,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:17,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741857_1033 src: /172.31.29.187:52918 dest: /172.31.29.187:50010
2021-11-04 11:38:17,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52918, dest: /172.31.29.187:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_577502487_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741857_1033, duration: 7376674
2021-11-04 11:38:17,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:17,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741858_1034 src: /172.31.29.187:52924 dest: /172.31.29.187:50010
2021-11-04 11:38:17,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52924, dest: /172.31.29.187:50010, bytes: 33758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_577502487_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741858_1034, duration: 7539788
2021-11-04 11:38:17,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:18,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741859_1035 src: /172.31.29.187:52928 dest: /172.31.29.187:50010
2021-11-04 11:38:18,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52928, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_577502487_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741859_1035, duration: 9939296
2021-11-04 11:38:18,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:19,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741860_1036 src: /172.31.29.187:52936 dest: /172.31.29.187:50010
2021-11-04 11:38:19,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52936, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741860_1036, duration: 6625394
2021-11-04 11:38:19,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:19,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741861_1037 src: /172.31.29.187:52940 dest: /172.31.29.187:50010
2021-11-04 11:38:19,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52940, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741861_1037, duration: 6489322
2021-11-04 11:38:19,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:19,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741862_1038 src: /172.31.29.187:52944 dest: /172.31.29.187:50010
2021-11-04 11:38:19,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52944, dest: /172.31.29.187:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741862_1038, duration: 3577311
2021-11-04 11:38:19,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:19,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741863_1039 src: /172.31.29.187:52948 dest: /172.31.29.187:50010
2021-11-04 11:38:19,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52948, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741863_1039, duration: 3559493
2021-11-04 11:38:19,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:23,041 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741855_1031
2021-11-04 11:38:23,062 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-11-04 11:38:23,062 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741852_1028 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741857_1033 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741857
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741848_1024 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741848
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741849_1025 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741849
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741850_1026 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741850
2021-11-04 11:38:23,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741851_1027 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741851
2021-11-04 11:38:23,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741852_1028 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741852
2021-11-04 11:38:23,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741855_1031 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741855
2021-11-04 11:38:23,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741864_1040 src: /172.31.29.187:52974 dest: /172.31.29.187:50010
2021-11-04 11:38:23,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52974, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415145142_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741864_1040, duration: 22086927
2021-11-04 11:38:23,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:25,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741865_1041 src: /172.31.29.187:52984 dest: /172.31.29.187:50010
2021-11-04 11:38:25,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52984, dest: /172.31.29.187:50010, bytes: 37670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1914183602_91, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741865_1041, duration: 4385049
2021-11-04 11:38:25,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:28,043 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741861_1037
2021-11-04 11:38:28,044 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741859_1035
2021-11-04 11:38:33,047 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741864_1040
2021-11-04 11:38:33,048 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741865_1041
2021-11-04 11:38:38,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741868_1044 src: /172.31.29.187:52994 dest: /172.31.29.187:50010
2021-11-04 11:38:45,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741869_1045 src: /172.31.18.188:44234 dest: /172.31.29.187:50010
2021-11-04 11:38:51,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44234, dest: /172.31.29.187:50010, bytes: 22675306, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0004_r_000000_0_113381232_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741869_1045, duration: 5944795350
2021-11-04 11:38:51,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:38:51,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:52994, dest: /172.31.29.187:50010, bytes: 33773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415145142_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741868_1044, duration: 12962297322
2021-11-04 11:38:51,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:51,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741870_1046 src: /172.31.29.187:53004 dest: /172.31.29.187:50010
2021-11-04 11:38:51,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53004, dest: /172.31.29.187:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415145142_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741870_1046, duration: 3699299
2021-11-04 11:38:51,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:51,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741871_1047 src: /172.31.29.187:53010 dest: /172.31.29.187:50010
2021-11-04 11:38:51,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53010, dest: /172.31.29.187:50010, bytes: 33773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415145142_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741871_1047, duration: 6875327
2021-11-04 11:38:51,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:51,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741872_1048 src: /172.31.29.187:53014 dest: /172.31.29.187:50010
2021-11-04 11:38:51,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53014, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415145142_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741872_1048, duration: 5553473
2021-11-04 11:38:51,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:53,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741873_1049 src: /172.31.29.187:53022 dest: /172.31.29.187:50010
2021-11-04 11:38:53,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53022, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741873_1049, duration: 6513145
2021-11-04 11:38:53,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:53,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741874_1050 src: /172.31.29.187:53026 dest: /172.31.29.187:50010
2021-11-04 11:38:53,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53026, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741874_1050, duration: 8400382
2021-11-04 11:38:53,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:53,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741875_1051 src: /172.31.29.187:53030 dest: /172.31.29.187:50010
2021-11-04 11:38:53,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53030, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741875_1051, duration: 3408907
2021-11-04 11:38:53,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:53,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741876_1052 src: /172.31.29.187:53034 dest: /172.31.29.187:50010
2021-11-04 11:38:53,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53034, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741876_1052, duration: 4596145
2021-11-04 11:38:53,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:56,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0) Starting thread to transfer BP-1852784058-172.31.29.187-1636025418820:blk_1073741873_1049 to 172.31.16.191:50010 
2021-11-04 11:38:56,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-1852784058-172.31.29.187-1636025418820:blk_1073741873_1049 (numBytes=21988) to /172.31.16.191:50010
2021-11-04 11:38:58,054 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741870_1046
2021-11-04 11:38:58,061 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741872_1048
2021-11-04 11:38:58,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741877_1053 src: /172.31.29.187:53048 dest: /172.31.29.187:50010
2021-11-04 11:38:58,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53048, dest: /172.31.29.187:50010, bytes: 35625, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_490553800_161, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741877_1053, duration: 11675214
2021-11-04 11:38:58,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741868_1044 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741860_1036 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741860
2021-11-04 11:38:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741861_1037 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741861
2021-11-04 11:38:59,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741862_1038 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741862
2021-11-04 11:38:59,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741863_1039 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741863
2021-11-04 11:38:59,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741864_1040 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741864
2021-11-04 11:38:59,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741868_1044 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741868
2021-11-04 11:38:59,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741879_1055 src: /172.31.18.188:44260 dest: /172.31.29.187:50010
2021-11-04 11:38:59,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44260, dest: /172.31.29.187:50010, bytes: 5413, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-880676139_89, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741879_1055, duration: 3380282
2021-11-04 11:38:59,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:38:59,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741880_1056 src: /172.31.16.191:55564 dest: /172.31.29.187:50010
2021-11-04 11:38:59,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55564, dest: /172.31.29.187:50010, bytes: 4601, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1930058974_89, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741880_1056, duration: 3317923
2021-11-04 11:38:59,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:39:03,064 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741875_1051
2021-11-04 11:39:03,064 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741873_1049
2021-11-04 11:39:08,067 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741877_1053
2021-11-04 11:39:08,067 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741880_1056
2021-11-04 11:39:14,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741881_1057 src: /172.31.18.188:44282 dest: /172.31.29.187:50010
2021-11-04 11:39:21,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741882_1058 src: /172.31.18.188:44294 dest: /172.31.29.187:50010
2021-11-04 11:39:27,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44294, dest: /172.31.29.187:50010, bytes: 22652393, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0005_r_000000_0_425355067_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741882_1058, duration: 6065622044
2021-11-04 11:39:27,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:39:27,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44282, dest: /172.31.29.187:50010, bytes: 33771, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1648196395_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741881_1057, duration: 13205652379
2021-11-04 11:39:27,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:39:27,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741884_1060 src: /172.31.18.188:44308 dest: /172.31.29.187:50010
2021-11-04 11:39:27,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44308, dest: /172.31.29.187:50010, bytes: 33771, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1648196395_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741884_1060, duration: 5579599
2021-11-04 11:39:27,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:39:28,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741886_1062 src: /172.31.29.187:53060 dest: /172.31.29.187:50010
2021-11-04 11:39:28,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53060, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741886_1062, duration: 3574684
2021-11-04 11:39:28,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741886_1062, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:39:28,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741887_1063 src: /172.31.29.187:53064 dest: /172.31.29.187:50010
2021-11-04 11:39:28,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53064, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741887_1063, duration: 7099011
2021-11-04 11:39:28,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741887_1063, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:39:28,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741888_1064 src: /172.31.29.187:53068 dest: /172.31.29.187:50010
2021-11-04 11:39:28,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53068, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741888_1064, duration: 4045634
2021-11-04 11:39:28,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741888_1064, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:39:28,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741889_1065 src: /172.31.29.187:53072 dest: /172.31.29.187:50010
2021-11-04 11:39:28,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53072, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741889_1065, duration: 5854829
2021-11-04 11:39:28,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:39:32,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0) Starting thread to transfer BP-1852784058-172.31.29.187-1636025418820:blk_1073741886_1062 to 172.31.18.188:50010 
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741873_1049 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741873 for deletion
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741874_1050 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741874 for deletion
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741875_1051 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741875 for deletion
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741876_1052 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741876 for deletion
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741881_1057 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741881 for deletion
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741873_1049 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741873
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741874_1050 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741874
2021-11-04 11:39:32,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741875_1051 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741875
2021-11-04 11:39:32,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741876_1052 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741876
2021-11-04 11:39:32,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741881_1057 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741881
2021-11-04 11:39:32,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-1852784058-172.31.29.187-1636025418820:blk_1073741886_1062 (numBytes=21988) to /172.31.18.188:50010
2021-11-04 11:39:35,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741891_1067 src: /172.31.18.188:44344 dest: /172.31.29.187:50010
2021-11-04 11:39:35,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44344, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2115714275_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741891_1067, duration: 45863211
2021-11-04 11:39:35,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741891_1067, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:39:50,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741892_1068 src: /172.31.18.188:44366 dest: /172.31.29.187:50010
2021-11-04 11:39:54,674 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741882_1058
2021-11-04 11:39:54,674 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741884_1060
2021-11-04 11:39:58,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741893_1069 src: /172.31.18.188:44378 dest: /172.31.29.187:50010
2021-11-04 11:39:59,677 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741889_1065
2021-11-04 11:39:59,678 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741891_1067
2021-11-04 11:40:05,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44378, dest: /172.31.29.187:50010, bytes: 22637445, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0006_r_000000_0_1263882565_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741893_1069, duration: 6098736860
2021-11-04 11:40:05,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741893_1069, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:40:05,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44366, dest: /172.31.29.187:50010, bytes: 33771, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2115714275_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741892_1068, duration: 14920032071
2021-11-04 11:40:05,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741892_1068, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:40:05,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741894_1070 src: /172.31.18.188:44386 dest: /172.31.29.187:50010
2021-11-04 11:40:05,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44386, dest: /172.31.29.187:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2115714275_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741894_1070, duration: 4204465
2021-11-04 11:40:05,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741894_1070, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:40:05,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741895_1071 src: /172.31.18.188:44392 dest: /172.31.29.187:50010
2021-11-04 11:40:05,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44392, dest: /172.31.29.187:50010, bytes: 33771, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2115714275_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741895_1071, duration: 3659584
2021-11-04 11:40:05,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741895_1071, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:40:07,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741897_1073 src: /172.31.29.187:53088 dest: /172.31.29.187:50010
2021-11-04 11:40:07,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53088, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741897_1073, duration: 7066359
2021-11-04 11:40:07,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741897_1073, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:07,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741898_1074 src: /172.31.29.187:53092 dest: /172.31.29.187:50010
2021-11-04 11:40:07,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53092, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741898_1074, duration: 8761937
2021-11-04 11:40:07,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741898_1074, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:07,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741899_1075 src: /172.31.29.187:53096 dest: /172.31.29.187:50010
2021-11-04 11:40:07,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53096, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741899_1075, duration: 9758302
2021-11-04 11:40:07,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741899_1075, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:07,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741900_1076 src: /172.31.29.187:53100 dest: /172.31.29.187:50010
2021-11-04 11:40:07,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53100, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741900_1076, duration: 8122155
2021-11-04 11:40:07,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741900_1076, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:11,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741901_1077 src: /172.31.29.187:53122 dest: /172.31.29.187:50010
2021-11-04 11:40:11,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53122, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-435408221_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741901_1077, duration: 35305808
2021-11-04 11:40:11,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741901_1077, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:14,682 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741899_1075
2021-11-04 11:40:14,683 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741892_1068
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741888_1064 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741888 for deletion
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741889_1065 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741889 for deletion
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741891_1067 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741891 for deletion
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741892_1068 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741892 for deletion
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741886_1062 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741886 for deletion
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741887_1063 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741887 for deletion
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741888_1064 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741888
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741889_1065 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741889
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741891_1067 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741891
2021-11-04 11:40:17,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741892_1068 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741892
2021-11-04 11:40:17,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741886_1062 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741886
2021-11-04 11:40:17,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741887_1063 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741887
2021-11-04 11:40:19,686 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741901_1077
2021-11-04 11:40:25,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741903_1079 src: /172.31.29.187:53146 dest: /172.31.29.187:50010
2021-11-04 11:40:26,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741894_1070 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741894 for deletion
2021-11-04 11:40:26,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741870_1046 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741870 for deletion
2021-11-04 11:40:26,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741894_1070 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741894
2021-11-04 11:40:26,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741870_1046 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741870
2021-11-04 11:40:39,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53146, dest: /172.31.29.187:50010, bytes: 33775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-435408221_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741903_1079, duration: 13087493781
2021-11-04 11:40:39,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741903_1079, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:39,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741905_1081 src: /172.31.29.187:53156 dest: /172.31.29.187:50010
2021-11-04 11:40:39,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53156, dest: /172.31.29.187:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-435408221_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741905_1081, duration: 4619516
2021-11-04 11:40:39,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741905_1081, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:39,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741906_1082 src: /172.31.29.187:53162 dest: /172.31.29.187:50010
2021-11-04 11:40:39,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53162, dest: /172.31.29.187:50010, bytes: 33775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-435408221_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741906_1082, duration: 4559509
2021-11-04 11:40:39,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741906_1082, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:39,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741907_1083 src: /172.31.29.187:53166 dest: /172.31.29.187:50010
2021-11-04 11:40:39,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53166, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-435408221_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741907_1083, duration: 6376198
2021-11-04 11:40:39,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741907_1083, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:40,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741908_1084 src: /172.31.29.187:53174 dest: /172.31.29.187:50010
2021-11-04 11:40:40,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53174, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741908_1084, duration: 6121929
2021-11-04 11:40:40,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741908_1084, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:40,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741909_1085 src: /172.31.29.187:53178 dest: /172.31.29.187:50010
2021-11-04 11:40:40,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53178, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741909_1085, duration: 11916353
2021-11-04 11:40:40,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741909_1085, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:40,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741910_1086 src: /172.31.29.187:53182 dest: /172.31.29.187:50010
2021-11-04 11:40:40,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53182, dest: /172.31.29.187:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741910_1086, duration: 4578868
2021-11-04 11:40:40,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741910_1086, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:40,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741911_1087 src: /172.31.29.187:53186 dest: /172.31.29.187:50010
2021-11-04 11:40:40,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53186, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741911_1087, duration: 6927747
2021-11-04 11:40:40,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741911_1087, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:44,693 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741906_1082
2021-11-04 11:40:44,694 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741903_1079
2021-11-04 11:40:45,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741912_1088 src: /172.31.29.187:53198 dest: /172.31.29.187:50010
2021-11-04 11:40:45,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53198, dest: /172.31.29.187:50010, bytes: 37672, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_509575431_205, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741912_1088, duration: 10004353
2021-11-04 11:40:45,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741912_1088, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:40:46,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741914_1090 src: /172.31.18.188:44464 dest: /172.31.29.187:50010
2021-11-04 11:40:46,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44464, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-656048339_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741914_1090, duration: 51796249
2021-11-04 11:40:46,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741914_1090, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:40:49,697 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741908_1084
2021-11-04 11:40:49,697 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741910_1086
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741897_1073 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741897 for deletion
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741898_1074 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741898 for deletion
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741899_1075 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741899 for deletion
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741897_1073 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741897
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741900_1076 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741900 for deletion
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741898_1074 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741898
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741901_1077 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741901 for deletion
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741899_1075 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741899
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741900_1076 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741900
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741901_1077 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741901
2021-11-04 11:40:50,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741903_1079 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741903 for deletion
2021-11-04 11:40:50,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741903_1079 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741903
2021-11-04 11:40:54,700 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741912_1088
2021-11-04 11:40:54,701 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741914_1090
2021-11-04 11:41:01,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741915_1091 src: /172.31.18.188:44474 dest: /172.31.29.187:50010
2021-11-04 11:41:08,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741916_1092 src: /172.31.16.191:55592 dest: /172.31.29.187:50010
2021-11-04 11:41:14,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55592, dest: /172.31.29.187:50010, bytes: 22629528, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0008_r_000000_0_154917715_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741916_1092, duration: 5833108905
2021-11-04 11:41:14,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741916_1092, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:14,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44474, dest: /172.31.29.187:50010, bytes: 33765, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-656048339_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741915_1091, duration: 13040951811
2021-11-04 11:41:14,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741915_1091, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:14,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741917_1093 src: /172.31.18.188:44484 dest: /172.31.29.187:50010
2021-11-04 11:41:14,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44484, dest: /172.31.29.187:50010, bytes: 346, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-656048339_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741917_1093, duration: 2978239
2021-11-04 11:41:14,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741917_1093, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:14,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741918_1094 src: /172.31.18.188:44490 dest: /172.31.29.187:50010
2021-11-04 11:41:14,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44490, dest: /172.31.29.187:50010, bytes: 33765, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-656048339_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741918_1094, duration: 3664734
2021-11-04 11:41:14,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741918_1094, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:16,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741920_1096 src: /172.31.29.187:53210 dest: /172.31.29.187:50010
2021-11-04 11:41:16,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53210, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741920_1096, duration: 9287664
2021-11-04 11:41:16,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741920_1096, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:16,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741921_1097 src: /172.31.29.187:53214 dest: /172.31.29.187:50010
2021-11-04 11:41:16,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53214, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741921_1097, duration: 14285162
2021-11-04 11:41:16,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741921_1097, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:16,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741922_1098 src: /172.31.29.187:53218 dest: /172.31.29.187:50010
2021-11-04 11:41:16,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53218, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741922_1098, duration: 3557841
2021-11-04 11:41:16,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741922_1098, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:16,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741923_1099 src: /172.31.29.187:53222 dest: /172.31.29.187:50010
2021-11-04 11:41:16,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53222, dest: /172.31.29.187:50010, bytes: 88708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741923_1099, duration: 6127295
2021-11-04 11:41:16,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741923_1099, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:19,708 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741915_1091
2021-11-04 11:41:19,708 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741918_1094
2021-11-04 11:41:22,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741924_1100 src: /172.31.16.191:55616 dest: /172.31.29.187:50010
2021-11-04 11:41:22,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741925_1101 src: /172.31.18.188:44502 dest: /172.31.29.187:50010
2021-11-04 11:41:22,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44502, dest: /172.31.29.187:50010, bytes: 35907, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-823209564_370, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741925_1101, duration: 4749884
2021-11-04 11:41:22,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741925_1101, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:22,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55616, dest: /172.31.29.187:50010, bytes: 105518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1847158381_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741924_1100, duration: 57048669
2021-11-04 11:41:22,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741924_1100, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:22,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741926_1102 src: /172.31.16.191:55622 dest: /172.31.29.187:50010
2021-11-04 11:41:22,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55622, dest: /172.31.29.187:50010, bytes: 9729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1909493208_187, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741926_1102, duration: 7307636
2021-11-04 11:41:22,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741926_1102, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:24,711 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741920_1096
2021-11-04 11:41:24,712 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741923_1099
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741908_1084 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741908 for deletion
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741909_1085 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741909 for deletion
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741910_1086 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741910 for deletion
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741911_1087 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741911 for deletion
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741914_1090 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741914 for deletion
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741915_1091 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741915 for deletion
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741908_1084 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741908
2021-11-04 11:41:26,073 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741909_1085 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741909
2021-11-04 11:41:26,074 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741910_1086 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741910
2021-11-04 11:41:26,074 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741911_1087 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741911
2021-11-04 11:41:26,074 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741914_1090 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741914
2021-11-04 11:41:26,074 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741915_1091 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741915
2021-11-04 11:41:29,715 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741924_1100
2021-11-04 11:41:29,715 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741925_1101
2021-11-04 11:41:33,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741927_1103 src: /172.31.16.191:55632 dest: /172.31.29.187:50010
2021-11-04 11:41:39,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741928_1104 src: /172.31.29.187:53254 dest: /172.31.29.187:50010
2021-11-04 11:41:43,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53254, dest: /172.31.29.187:50010, bytes: 22629726, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0009_r_000000_0_-2106869030_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741928_1104, duration: 4558527251
2021-11-04 11:41:43,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741928_1104, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:43,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55632, dest: /172.31.29.187:50010, bytes: 33775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1847158381_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741927_1103, duration: 10120415510
2021-11-04 11:41:43,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741927_1103, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:43,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741930_1106 src: /172.31.16.191:55648 dest: /172.31.29.187:50010
2021-11-04 11:41:43,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55648, dest: /172.31.29.187:50010, bytes: 33775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1847158381_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741930_1106, duration: 3916894
2021-11-04 11:41:43,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741930_1106, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:45,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741932_1108 src: /172.31.29.187:53262 dest: /172.31.29.187:50010
2021-11-04 11:41:45,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53262, dest: /172.31.29.187:50010, bytes: 21988, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741932_1108, duration: 3692063
2021-11-04 11:41:45,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741932_1108, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:45,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741933_1109 src: /172.31.29.187:53266 dest: /172.31.29.187:50010
2021-11-04 11:41:45,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53266, dest: /172.31.29.187:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741933_1109, duration: 6472183
2021-11-04 11:41:45,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741933_1109, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:45,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741934_1110 src: /172.31.29.187:53270 dest: /172.31.29.187:50010
2021-11-04 11:41:45,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53270, dest: /172.31.29.187:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741934_1110, duration: 3385490
2021-11-04 11:41:45,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741934_1110, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:45,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741935_1111 src: /172.31.29.187:53274 dest: /172.31.29.187:50010
2021-11-04 11:41:45,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53274, dest: /172.31.29.187:50010, bytes: 88568, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859153996_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741935_1111, duration: 6422129
2021-11-04 11:41:45,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741935_1111, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:49,722 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741930_1106
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741920_1096 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741920 for deletion
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741921_1097 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741921 for deletion
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741922_1098 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741922 for deletion
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741923_1099 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741923 for deletion
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741924_1100 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741924 for deletion
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741920_1096 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741920
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741927_1103 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741927 for deletion
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741921_1097 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741921
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741922_1098 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741922
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741923_1099 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741923
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741924_1100 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741924
2021-11-04 11:41:50,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741927_1103 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741927
2021-11-04 11:41:50,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741936_1112 src: /172.31.16.191:55660 dest: /172.31.29.187:50010
2021-11-04 11:41:50,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.16.191:55660, dest: /172.31.29.187:50010, bytes: 35259, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1431087831_220, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741936_1112, duration: 3430906
2021-11-04 11:41:50,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741936_1112, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:41:50,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741937_1113 src: /172.31.29.187:53286 dest: /172.31.29.187:50010
2021-11-04 11:41:50,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53286, dest: /172.31.29.187:50010, bytes: 10118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_690388980_205, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741937_1113, duration: 4893764
2021-11-04 11:41:50,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741937_1113, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:41:53,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0) Starting thread to transfer BP-1852784058-172.31.29.187-1636025418820:blk_1073741932_1108 to 172.31.18.188:50010 
2021-11-04 11:41:53,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer: Transmitted BP-1852784058-172.31.29.187-1636025418820:blk_1073741932_1108 (numBytes=21988) to /172.31.18.188:50010
2021-11-04 11:41:59,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741939_1115 src: /172.31.18.188:44534 dest: /172.31.29.187:50010
2021-11-04 11:42:04,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116 src: /172.31.29.187:53310 dest: /172.31.29.187:50010
2021-11-04 11:42:04,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53310, dest: /172.31.29.187:50010, bytes: 7333875, op: HDFS_WRITE, cliID: DFSClient_attempt_1636025479498_0010_r_000000_0_-813601406_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116, duration: 450586292
2021-11-04 11:42:04,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:42:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44534, dest: /172.31.29.187:50010, bytes: 33652, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570878191_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741939_1115, duration: 5459657784
2021-11-04 11:42:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741939_1115, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:42:04,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741941_1117 src: /172.31.18.188:44542 dest: /172.31.29.187:50010
2021-11-04 11:42:04,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44542, dest: /172.31.29.187:50010, bytes: 345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570878191_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741941_1117, duration: 5623027
2021-11-04 11:42:04,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741941_1117, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:42:04,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741942_1118 src: /172.31.18.188:44548 dest: /172.31.29.187:50010
2021-11-04 11:42:04,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44548, dest: /172.31.29.187:50010, bytes: 33652, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570878191_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741942_1118, duration: 3282103
2021-11-04 11:42:04,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741942_1118, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:42:04,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741943_1119 src: /172.31.18.188:44552 dest: /172.31.29.187:50010
2021-11-04 11:42:04,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.18.188:44552, dest: /172.31.29.187:50010, bytes: 105354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-570878191_1, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741943_1119, duration: 11859959
2021-11-04 11:42:04,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741943_1119, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-11-04 11:42:11,322 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741928_1104
2021-11-04 11:42:12,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1852784058-172.31.29.187-1636025418820:blk_1073741946_1122 src: /172.31.29.187:53320 dest: /172.31.29.187:50010
2021-11-04 11:42:12,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.31.29.187:53320, dest: /172.31.29.187:50010, bytes: 6067, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_244602051_205, offset: 0, srvID: 19b9991c-5f77-4ac9-a12c-f97983ab83b8, blockid: BP-1852784058-172.31.29.187-1636025418820:blk_1073741946_1122, duration: 4042162
2021-11-04 11:42:12,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1852784058-172.31.29.187-1636025418820:blk_1073741946_1122, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741939_1115 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741939 for deletion
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741932_1108 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741932 for deletion
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741933_1109 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741933 for deletion
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741934_1110 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741934 for deletion
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741939_1115 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741939
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741935_1111 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741935 for deletion
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741932_1108 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741932
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741933_1109 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741933
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741934_1110 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741934
2021-11-04 11:42:14,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741935_1111 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741935
2021-11-04 11:42:16,325 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741941_1117
2021-11-04 11:42:16,325 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741936_1112
2021-11-04 11:42:21,327 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-1852784058-172.31.29.187-1636025418820:blk_1073741946_1122
2021-11-04 11:43:26,081 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741905_1081 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741905 for deletion
2021-11-04 11:43:26,081 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741941_1117 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741941 for deletion
2021-11-04 11:43:26,081 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741917_1093 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741917 for deletion
2021-11-04 11:43:26,082 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741905_1081 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741905
2021-11-04 11:43:26,082 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741941_1117 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741941
2021-11-04 11:43:26,082 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1852784058-172.31.29.187-1636025418820 blk_1073741917_1093 file /tmp/hadoop-ubuntu/dfs/data/current/BP-1852784058-172.31.29.187-1636025418820/current/finalized/subdir0/subdir0/blk_1073741917
2021-11-04 11:58:24,958 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1852784058-172.31.29.187-1636025418820 Total blocks: 34, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-11-04 13:21:07,994 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:21:08,366 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:31:08,000 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:31:08,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:41:08,003 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:41:08,442 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:51:08,006 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 13:51:08,473 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:01:08,010 WARN org.apache.hadoop.util.Shell: Could not get disk usage information
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:01:08,510 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU.parseExecResult(DU.java:233)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.fs.DU.run(DU.java:190)
	at org.apache.hadoop.fs.DU$DURefreshThread.run(DU.java:119)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:08:30,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting CheckDiskError Thread
2021-11-04 14:08:30,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116 received exception java.io.IOException: BlockId 1073741940 is not valid.
2021-11-04 14:08:30,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0):Got exception while serving BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116 to /172.31.29.187:54288
java.io.IOException: BlockId 1073741940 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:08:30,393 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:54288 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741940 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:08:31,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opReadBlock BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116 received exception java.io.IOException: BlockId 1073741940 is not valid.
2021-11-04 14:08:31,530 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.31.29.187, datanodeUuid=19b9991c-5f77-4ac9-a12c-f97983ab83b8, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-f53649fe-be05-46fe-bf10-25b2d6c6a3af;nsid=1798636716;c=0):Got exception while serving BP-1852784058-172.31.29.187-1636025418820:blk_1073741940_1116 to /172.31.29.187:54292
java.io.IOException: BlockId 1073741940 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:08:31,530 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: hadoopmaster:50010:DataXceiver error processing READ_BLOCK operation  src: /172.31.29.187:54292 dst: /172.31.29.187:50010
java.io.IOException: BlockId 1073741940 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:566)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockFile(FsDatasetImpl.java:557)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:205)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:276)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:514)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:239)
	at java.lang.Thread.run(Thread.java:748)
2021-11-04 14:08:54,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-11-04 14:08:54,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-11-04 14:08:55,432 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-11-04 14:08:55,521 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-11-04 14:08:55,521 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-11-04 14:08:55,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-11-04 14:08:55,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-11-04 14:08:55,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-11-04 14:08:55,548 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:720)
	at org.apache.hadoop.ipc.Server.bind(Server.java:424)
	at org.apache.hadoop.ipc.Server.bind(Server.java:396)
	at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:111)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:871)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1084)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2328)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2215)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2262)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2438)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2462)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:461)
	at sun.nio.ch.Net.bind(Net.java:453)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:222)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:85)
	at org.apache.hadoop.ipc.Server.bind(Server.java:407)
	... 10 more
2021-11-04 14:08:55,551 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-11-04 14:08:55,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-11-04 14:10:33,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = hadoopmaster/172.31.29.187
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.4
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.4.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6; compiled by 'jenkins' on 2016-02-12T09:45Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-11-04 14:10:33,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-11-04 14:10:33,950 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-11-04 14:10:34,048 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-11-04 14:10:34,048 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-11-04 14:10:34,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoopmaster
2021-11-04 14:10:34,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-11-04 14:10:34,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-11-04 14:10:34,079 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:720)
	at org.apache.hadoop.ipc.Server.bind(Server.java:424)
	at org.apache.hadoop.ipc.Server.bind(Server.java:396)
	at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:111)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:871)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1084)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2328)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2215)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2262)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2438)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2462)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:461)
	at sun.nio.ch.Net.bind(Net.java:453)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:222)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:85)
	at org.apache.hadoop.ipc.Server.bind(Server.java:407)
	... 10 more
2021-11-04 14:10:34,082 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-11-04 14:10:34,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
2021-11-04 14:16:50,868 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-11-04 14:16:50,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at hadoopmaster/172.31.29.187
************************************************************/
